{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_fine_train = (\"./datasets_csv/finetuning/train\")\n",
    "csv_path_fine_test = (\"./datasets_csv/finetuning/test\")\n",
    "csv_path_pred_labeling = (\"./datasets_csv/pred_labeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date                                              title  \\\n",
      "0   2020-07-25 11:08:00  エンタメ業界は苦しい。でも…　「新型コロナ以前の世界が戻ってくることはない」エイベックスが見...   \n",
      "1   2020-08-03 06:10:00                    オンラインライブ配信はウィズコロナ時代の救世主になれるのか\\n   \n",
      "2   2020-08-11 19:35:00  米Twitchでの音楽使用料に関してミュージシャンから親会社アマゾンのジェフ・ベゾスへ公開書簡\\n   \n",
      "3   2020-09-28 18:20:00  クラシック音楽界の概念を超えた大型オンラインフェスのレポート到着　アーティストによるライブ＆...   \n",
      "4   2020-10-28 08:00:00    「鬼滅の刃」人気は株式市場にも影響　たまごっち登場、グッズ関連にぎわう…“鬼滅銘柄”を物色\\n   \n",
      "5   2020-10-29 08:10:00                  ソニー好決算「上方修正」。その強みはこの1枚のスライドでわかる\\n   \n",
      "6   2020-11-05 16:24:00                                  エイベックス、初の希望退職募集\\n   \n",
      "7   2020-11-06 12:46:00               エイベックスが初の希望退職募集　コロナ禍でライブ・舞台関連事業に打撃\\n   \n",
      "8   2020-11-07 17:01:00                 嵐や白石麻衣は大成功、音楽業界の「勝ち組」がごく一部だという現実\\n   \n",
      "9   2020-11-17 07:00:00           電子チケット販売に自由を。ZAIKO COOが見据える「D2F」という勝ち筋\\n   \n",
      "10  2020-12-10 19:15:00                      音楽業界の未来、実はストリーミングではなくSNSが重要\\n   \n",
      "11  2020-12-21 18:42:00     浜崎あゆみ、クリスマスと大みそかライブの有観客断念を発表　無観客生配信へ「残念ながら…」\\n   \n",
      "12  2020-12-24 15:24:00            エイベックス、本社ビルの売却を発表　通期の純利益は150億円の黒字に転換へ\\n   \n",
      "13  2020-12-25 01:06:00  エイベックス(7860)、「増配」を発表し、配当利回り11.1％に！ 年間配当は1年間で2....   \n",
      "14  2021-01-02 08:02:00          エイベックス本社ビルが「築3年」で売却　入札額トップが落札できなかった奇々怪々\\n   \n",
      "15  2021-01-06 19:00:00  芸能イベントも続々中止・無観客に　今週末開催の『銀魂』『約ネバ』『セーラームーン』舞台あいさ...   \n",
      "16  2021-01-08 09:00:00                     2021年、日本アニメが世界トレンドへ飛躍する節目の年に\\n   \n",
      "17  2021-01-13 11:26:00     ソニー、クリエイティブなエンターテインメント企業へ--世界4拠点からプレスカンファレンス\\n   \n",
      "18  2021-01-13 13:45:00  エイベックス、中国bilibiliとライセンス契約　J-POPのMVを提供　日本の大手レーベ...   \n",
      "19  2021-01-19 15:52:00                 コロナで収入源を失ったプロミュージシャン、過去作を現金化する動き\\n   \n",
      "\n",
      "                                                 text  \n",
      "0   新型コロナウイルスは日本のエンターテインメント業界にも大きな影響を及ぼした。相次ぐライブやイ...  \n",
      "1   新型コロナ感染症の影響で、会場で行われる音楽ライブや演劇、スポーツイベントなどが軒並み苦戦を...  \n",
      "2   　アマゾンの創設者でCEOのジェフ・ベゾスは、先月末の議会聴聞会の証言で、同社の傘下にあるラ...  \n",
      "3   クラシック音楽界の概念を超えた大型オンラインフェスのレポート到着　アーティストによるライブ＆...  \n",
      "4   　少し前までは「鬼滅の刃」を、どう読んでいいか分からなかった大人でも、いまではもう「きめつの...  \n",
      "5   ソニーがコロナ禍の中間決算でも好調だ。\\n10月28日に発表した2021年3月期の2Q決算で...  \n",
      "6   　音楽・映像事業を手掛けるエイベックス（株）（TSR企業コード:294000011、港区、東...  \n",
      "7   　音楽関連の事業を手掛けるエイベックスは11月5日、初の希望退職を募集すると発表しました。同...  \n",
      "8   　全国のファンを釘付けにした、活動休止前の嵐による実質的なラストライブ『アラフェス2020 ...  \n",
      "9   ZAIKO取締役COO　Lauren Rose Kocher氏\\nライブの軒並み中止や、配信...  \n",
      "10  先見の明がある投資家たちの資金が集まるオンラインでのカラオケや音楽制作が、音楽業界にとってま...  \n",
      "11  　歌手の浜崎あゆみの公式サイトが21日に更新。クリスマスの「ayumi hamasaki L...  \n",
      "12  希望退職制度の応募人数は103名\\n　音楽・映像事業を手掛けるエイベックス（株）（TSR企業...  \n",
      "13  　エイベックスは、2021年3月期の配当予想を修正し、前期比で「増配」とする予想を、2020...  \n",
      "14  銀行主導のもと進められた売却プラン\\n売却情報が流れ始めたのは、浜崎あゆみがエイベックス・松...  \n",
      "15  　新型コロナウイルス感染の拡大、翌7日に東京都と埼玉、千葉、神奈川3県を対象とする緊急事態宣...  \n",
      "16  　2020年の最大ヒットコンテンツとなった『鬼滅の刃』。原作コミックは最終23巻で1億200...  \n",
      "17  　ソニーは1月11日午後5時（米国東部時間）から、「CES 2021」においてプレスカンファ...  \n",
      "18  　エイベックスは1月13日、同社の子会社を通じて中国の動画配信サイト「bilibili」を運...  \n",
      "19  英国の作曲家でプロデューサーのイアン・レビン氏が英ポップグループ、「テイク・ザット」（写真）...  \n"
     ]
    }
   ],
   "source": [
    "# ニュース記事\n",
    "\n",
    "#df_finetuning_news = pd.read_csv(csv_path_fine + '/news/news_dataset.csv')\n",
    "df_train_news = pd.read_csv(csv_path_pred_labeling + '/news/news_dataset.csv')\n",
    "\n",
    "#print(df_finetuning_news)\n",
    "print(df_train_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning train:\n",
      "                                                  text reply good bad\n",
      "0   ハロプロの事務所も昨年末に移転しましたよね\\n都内から都内だけど、複数の拠点を1拠点にまとめ...     1  278  53\n",
      "1   日本の芸能プロダクションも\\nアメリカのエージェントシステムに\\n移行していますね！\\nタレ...     0  235  45\n",
      "2   エイベックスの件はともかくこれから都心の地価は下がるのではないか。これだけリモートワークが推...     3  120  17\n",
      "3   その昔大学が都心から郊外や県外に脱出しました（中央大学や筑波大学など）。その結果として、人気...     1  107  20\n",
      "4   河口湖は東京都心からやや遠いけれど、都心回帰で空きが増えた八王子の大学のキャンパスなんか移転...     2   70   5\n",
      "..                                                ...   ...  ...  ..\n",
      "56                            本当ただの妄想コントでしかない記事だね\\n\\n     0   17   0\n",
      "57                                   浅草をバカにしてるのか？\\n\\n     0   18   1\n",
      "58                 日本のショービジネスの人間はアマチュア。\\n辞めた方が良い。\\n\\n     0   11   3\n",
      "59                                     足立区でよいのでは？\\n\\n     1   10   6\n",
      "60                                八王子あたりでよくない？(笑)\\n\\n     0   21   8\n",
      "\n",
      "[61 rows x 4 columns]\n",
      "finetuning test:\n",
      "                                                 text reply good bad\n",
      "0  役員報酬がバカ高く上層部ばかりが得する仕組みをやってる会社はどこも衰退していくよ。今回社員を...     0  148  16\n",
      "1  もう、馬鹿タレを法外な価格で売りつけ・使うビジネスは、コロナ無くても先細りだった。タレを囲い...     0   50  21\n",
      "2          どの会社でも言えることだけど、希望退職募ると有能から抜けてくからなぁ。。。\\n\\n     0   59  11\n",
      "3  コロナと言うよりは、時代の流れ。\\n時代の流れに乗れない企業は、特にコロナと言う波に耐えられ...     0  105  29\n",
      "4          建物があることに価値がある時代が変わってくるんだろう\\nテレワークの時代で\\n\\n     0    1   0\n",
      "5                 まあ\\nこれまでのツケを\\n返してマイナスになる時が来たな。\\n\\n     0   44   8\n",
      "6             芸能界は飽きられた\\n\\n広告もネットに散った\\n\\n先細りの運命か\\n\\n     0   47   7\n",
      "7                              エイベックスのやり方はもう時代遅れ\\n\\n     0   33   5\n",
      "8                          盛者必衰の理を現す。　もう「時代」じゃ無い\\n\\n     0   34  15\n",
      "9  エイベックスってビル建てて引っ越したばっかりだろ？\\n流石にこれは気の毒としか言いようがない...     0    7  17\n"
     ]
    }
   ],
   "source": [
    "# ニュースコメント\n",
    "\n",
    "import os\n",
    "\n",
    "csv_folder = [csv_path_fine_train , csv_path_fine_test, csv_path_pred_labeling]\n",
    "\n",
    "file_count = 0\n",
    "for p in csv_folder:\n",
    "    file_count += sum((len(f) for _, _, f in os.walk(p + '/comments'))) - 1\n",
    "#print(file_count)\n",
    "\n",
    "for j, p in enumerate(csv_folder):\n",
    "    cols = ['text', 'reply', 'good', 'bad']\n",
    "    df_temp = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for i in range(file_count):\n",
    "        n_file = str(i+1).zfill(3)\n",
    "        file_name = \"comment_dataset_\" + n_file + \".csv\"\n",
    "        file_path = (p + \"/comments/\" + file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        #print(str(i+1).zfill(3))#あとで消す\n",
    "        df_cmt = pd.read_csv(file_path, index_col=0)\n",
    "        #df_temp = pd.concat([df_temp, df_cmt], ignore_index=True)\n",
    "              \n",
    "        #代入\n",
    "        if j <= 1:\n",
    "            df_temp = pd.concat([df_temp, df_cmt], ignore_index=True)\n",
    "        else:\n",
    "            df_cmt.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "            df_cmt[[\"feature\", \"good\", \"bad\"]].to_csv(\"./datasets/pred_labeling/features_\" + n_file + \".csv\", index=False)\n",
    "            #df_pred_comments = df_temp.copy()\n",
    "        \n",
    "    #代入\n",
    "    if j == 0:\n",
    "        df_fine_train_comments = df_temp.copy()\n",
    "    elif j == 1:\n",
    "        df_fine_test_comments = df_temp.copy()\n",
    "        \n",
    "print(\"finetuning train:\\n\", df_fine_train_comments)\n",
    "print(\"finetuning test:\\n\", df_fine_test_comments)\n",
    "#print(\"pred labeling:\\n\", df_pred_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels train:\n",
      "        label\n",
      "0   positive\n",
      "1   positive\n",
      "2   positive\n",
      "3   negative\n",
      "4   positive\n",
      "..       ...\n",
      "56  negative\n",
      "57  negative\n",
      "58  negative\n",
      "59  negative\n",
      "60  negative\n",
      "\n",
      "[61 rows x 1 columns]\n",
      "labels test:\n",
      "       label\n",
      "0  negative\n",
      "1  negative\n",
      "2  negative\n",
      "3  negative\n",
      "4  positive\n",
      "5  negative\n",
      "6  negative\n",
      "7  negative\n",
      "8  negative\n",
      "9  positive\n"
     ]
    }
   ],
   "source": [
    "#ラベル\n",
    "import os\n",
    "\n",
    "csv_folder = [csv_path_fine_train , csv_path_fine_test]\n",
    "\n",
    "#file_count = 0\n",
    "#for p in csv_folder:\n",
    "#    file_count += sum((len(f) for _, _, f in os.walk(p + '/comments'))) - 1\n",
    "#print(file_count)\n",
    "\n",
    "for j, p in enumerate(csv_folder):\n",
    "    cols = ['label']\n",
    "    df_temp = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for i in range(file_count):\n",
    "        n_file = str(i+1).zfill(3)\n",
    "        file_name = \"comment_labels_\" + n_file + \".csv\"\n",
    "        file_path = (p + \"/labels/\" + file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        #print(str(i+1).zfill(3))#あとで消す\n",
    "        df_labels = pd.read_csv(file_path)#, index_col=0\n",
    "        # concat\n",
    "        #print(df_labels)\n",
    "        df_temp = pd.concat([df_temp, df_labels], ignore_index=True)\n",
    "\n",
    "    #代入\n",
    "    if j == 0:\n",
    "        df_fine_train_labels = df_temp.copy()\n",
    "    elif j == 1:\n",
    "        df_fine_test_labels = df_temp.copy()\n",
    "        \n",
    "print(\"labels train:\\n\", df_fine_train_labels)\n",
    "print(\"labels test:\\n\", df_fine_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成と保存\n",
    "\n",
    "datasets_folder =  (\"./datasets/finetuning\")\n",
    "\n",
    "\n",
    "#print(\"finetuning train:\\n\", df_fine_train_comments)\n",
    "#print(\"finetuning test:\\n\", df_fine_test_comments)\n",
    "#print(\"pred labeling:\\n\", df_pred_comments)\n",
    "\n",
    "df_fine_train_comments.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "df_fine_train_comments[\"feature\"].to_csv(datasets_folder + \"/train/features.csv\", index=False)\n",
    "\n",
    "df_fine_test_comments.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "df_fine_test_comments[\"feature\"].to_csv(datasets_folder + \"/test/features.csv\", index=False)\n",
    "\n",
    "#print(\"labels train:\\n\", df_fine_train_labels)\n",
    "#print(\"labels test:\\n\", df_fine_test_labels)\n",
    "\n",
    "df_fine_train_labels[\"label\"].to_csv(datasets_folder + \"/train/labels.csv\", index=False)\n",
    "df_fine_test_labels[\"label\"].to_csv(datasets_folder + \"/test/labels.csv\", index=False)\n",
    "\n",
    "# 上に持っていく\n",
    "#df_pred_comments.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "#df_pred_comments[\"feature\"].to_csv(\"./datasets/pred_labeling/features.csv\", index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#表示用\n",
    "#news_file_path = (p + \"/labels/\" + file_name)\n",
    "#df_cmt = pd.read_csv(news_file_path, index_col=0)\n",
    "#df_temp = pd.concat([df_temp, df_cmt], ignore_index=True)\n",
    "#\n",
    "#dsp_df_fine_train_comments = df_fine_train_comments[\"feature\"]\n",
    "#dsp_df_fine_train_labels = df_fine_train_labels[\"label\"]\n",
    "#dsp_df_pred_comments = df_pred_comments[\"feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ニュースの例\n",
    "#dsp_df_pred_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コメントの例（上のニュースとは無関係）\n",
    "#dsp_df_fine_train_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルの例（上のニュースとは無関係）\n",
    "#dsp_df_fine_train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語分割する関数を定義\n",
    "import MeCab\n",
    "import re\n",
    "import string\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    '''\n",
    "    前処理\n",
    "    '''\n",
    "    # 改行コードを消去\n",
    "    text = re.sub('<br />', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "            \n",
    "    for p in string.punctuation:\n",
    "        if (p == \"。\") or (p == \"、\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \"　\")\n",
    "            \n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"。\", \" 。 \")\n",
    "    text = text.replace(\"、\", \" 、 \")\n",
    "    \n",
    "    return text\n",
    "\n",
    "#m_t = MeCab.Tagger('-Owakati -d /usr/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "#m_t = MeCab.Tagger('-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "wakati = MeCab.Tagger(\"-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "\n",
    "def tokenizer_mecab(text):\n",
    "    '''\n",
    "    分かち書き\n",
    "    '''\n",
    "    words = wakati.parse(text).split()\n",
    "    \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized:\n",
      " ['機械学習', 'が', '好き', 'です', '。', '＋', '＋', '？？？', '：', '：', '機械学習', 'が', '好き', 'です', '。']\n"
     ]
    }
   ],
   "source": [
    "text = '機械学習が好きです。\\n＋＋？？？：：機械学習が好きです。'\n",
    "\n",
    "pre_text = preprocessing_text(text)\n",
    "tokenized_text = tokenizer_mecab(pre_text)\n",
    "print(\"tokenized:\\n\", tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre:\n",
      " 機械学習が好きです 。 ＋＋？？？：：機械学習が好きです 。 \n",
      "tokenized:\n",
      " ['機械学習', 'が', '好き', 'です', '。', '＋', '＋', '？？？', '：', '：', '機械学習', 'が', '好き', 'です', '。']\n",
      "text tokenized:\n",
      " 15\n"
     ]
    }
   ],
   "source": [
    "text = '機械学習が好きです。\\n＋＋？？？：：機械学習が好きです。'\n",
    "\n",
    "pre_text = preprocessing_text(text)\n",
    "print(\"pre:\\n\", pre_text)\n",
    "tokenized_text = tokenizer_mecab(pre_text)\n",
    "print(\"tokenized:\\n\", tokenized_text)\n",
    "print(\"text tokenized:\\n\", len(tokenized_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの表示(一旦保留)\n",
    "\n",
    "#df_finetuning_news[\"feature\"] = df_finetuning_news[\"title\"] +  df_finetuning_news[\"text\"]\n",
    "#df_finetuning_news = df_finetuning_news[\"feature\"].copy()\n",
    "#print(df_finetuning_news)\n",
    "\n",
    "\n",
    "#df_train_news[\"feature\"] = df_train_news[\"title\"] +  df_train_news[\"text\"]\n",
    "#df_train_news = df_train_news[\"feature\"].copy()\n",
    "#print(df_train_news)\n",
    "#\n",
    "#df_finetuning_comments.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "#df_finetuning_comments = df_finetuning_comments[\"feature\"].copy()\n",
    "#print(df_finetuning_comments)\n",
    "#\n",
    "#df_train_comments.columns = [\"feature\", \"reply\", \"good\", \"bad\"]\n",
    "#df_train_comments = df_train_comments[\"feature\"].copy()\n",
    "#print(df_train_comments)\n",
    "#\n",
    "#df_finetuning_labels = df_finetuning_labels[\"label\"].copy()\n",
    "#print(df_finetuning_labels)\n",
    "#\n",
    "# return (df_finetuning_news[\"feature\"], \n",
    "#                df_train_news[\"feature\"], \n",
    "#                df_finetuning_comments[\"text\"], \n",
    "#                df_train_comments[\"text\"],\n",
    "#                df_finetuning_labels[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_comments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_comments[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_finetuning_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bert-tensorflow\n",
    "#!pip install keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tech-blog.cloud-config.jp/2020-02-06-category-classification-using-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone --recurse-submodules https://github.com/yoheikikuta/bert-japanese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定ファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features_df:\n",
      "                                               feature\n",
      "0   ハロプロの事務所も昨年末に移転しましたよね\\n都内から都内だけど、複数の拠点を1拠点にまとめ...\n",
      "1   日本の芸能プロダクションも\\nアメリカのエージェントシステムに\\n移行していますね！\\nタレ...\n",
      "2   エイベックスの件はともかくこれから都心の地価は下がるのではないか。これだけリモートワークが推...\n",
      "3   その昔大学が都心から郊外や県外に脱出しました（中央大学や筑波大学など）。その結果として、人気...\n",
      "4   河口湖は東京都心からやや遠いけれど、都心回帰で空きが増えた八王子の大学のキャンパスなんか移転...\n",
      "..                                                ...\n",
      "56                            本当ただの妄想コントでしかない記事だね\\n\\n\n",
      "57                                   浅草をバカにしてるのか？\\n\\n\n",
      "58                 日本のショービジネスの人間はアマチュア。\\n辞めた方が良い。\\n\\n\n",
      "59                                     足立区でよいのでは？\\n\\n\n",
      "60                                八王子あたりでよくない？(笑)\\n\\n\n",
      "\n",
      "[61 rows x 1 columns]\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'ハロプロ', 'の', '事務所', 'も', '昨年末', 'に', '移転', 'し', 'まし', 'た', 'よ', 'ね', '都内', 'から', '都内', 'だ', 'けど', '、', '複数', 'の', '拠点', 'を', '1', '拠点', 'に', 'まとめ', 'た', 'みたい', '経営', '立て直し', 'する', '上', 'で', '、', '固定費', 'の', '中', 'で', 'も', 'まず', '着手', 'する', 'の', 'は', '家賃', 'です', 'から', 'ね', '。', 'しんどい', '状況', 'です', 'が', '頑張っ', 'て', '欲しい', 'です', 'ね', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '日本', 'の', '芸能プロダクション', 'も', 'アメリカ', 'の', 'エージェント', 'システム', 'に', '移行', 'し', 'て', 'い', 'ます', 'ね', '！', 'タレント', 'が', 'エージェント', 'を', '雇う', '！', '立場', 'が', '逆転', 'する', 'わけ', 'です', 'が', '1世紀', 'かけ', 'て', '本来', 'の', 'マネジメント', 'の', '姿', 'に', '戻る', '訳', 'です', 'ね', '！', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'エイベックス', 'の', '件', 'は', 'ともかく', 'これから', '都心', 'の', '地価', 'は', '下がる', 'の', 'で', 'は', 'ない', 'か', '。', 'これだけ', 'リモートワーク', 'が', '推奨', 'さ', 'れ', 'かつ', '円滑', 'に', '仕事', 'が', '進む', 'よう', 'なら', '都心', 'に', '事務所', 'を', '構え', 'て', 'いる', '会社', 'の', '多く', 'は', '売却', 'や', '移転', 'を', 'する', 'なら', '考える', 'の', 'は', '普通', 'の', '流れ', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'その昔', '大学', 'が', '都心', 'から', '郊外', 'や', '県外', 'に', '脱出', 'し', 'まし', 'た', '（', '中央大学', 'や', '筑波大学', 'など', '）', '。', 'その', '結果', 'として', '、', '人気', 'が', '出', 'た', '大学', 'は', 'ほとんど', 'なく', '、', '結果的', 'に', '大学', 'ランキング', 'で', 'も', '上位', 'を', '占める', 'こと', 'が', 'だんだん', 'と', '難しく', 'なっ', 'た', '過去', 'が', 'あり', 'ます', '。', '今', 'は', 'その', '反省', 'な', 'の', 'か', '少子化対策', 'なのか', '、', '学生', '集め', 'に', '必死', 'な', '大学', 'は', '東京駅', 'の', 'すぐ', '近く', 'に', 'キャンパス', 'と', 'は', '呼べ', 'ない', 'ビル', 'の', 'フロア', 'を', '借り', 'てる', 'ぐらい', 'です', '。', '芸能事務所', 'が', '同じ', 'と', 'は', '思い', 'ませ', 'ん', 'が', '、', '単に', '田舎', 'に', '引っ越す', 'の', 'で', 'あれ', 'ば', '、', 'それ', 'は', 'コスト削減', '以外', 'に', 'は', '意味', 'が', 'ない', 'でしょ', 'う', '。', '空気', 'が', '綺麗', 'な', 'の', 'と', '、', 'タレント', 'が', '仕事', 'を', 'し', 'やすかっ', 'たり', '、', '事務所', 'が', '反映', 'する', 'こと', 'は', '関係', 'が', 'ない', 'です', 'から', '。', '結局', '、', '支社', 'という', 'こと', 'で', '東京', 'に', '小さな', 'オフィス', 'は', '借りる', 'ん', 'だ', 'と', '思い', 'ます', '。', '間', 'を', 'とっ', 'て', '浅草', 'という', 'の', 'は', 'アイデア', 'の', '一つ', 'だ', 'と', '思い', 'ます', '。', '移動', 'に', 'は', '便利', 'で', '不動産', '価格', 'も', 'ビジネス街', 'より', 'は', '高く', 'は', 'ない', 'です', 'から', '。', 'あと', 'は', 'その', '街', 'を', '好き', 'か', 'どう', 'か', 'だけ', 'な', 'ので', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '河口湖', 'は', '東京都', '心', 'から', 'やや', '遠い', 'けれど', '、', '都心回帰', 'で', '空き', 'が', '増え', 'た', '八王子', 'の', '大学', 'の', 'キャンパス', 'なんか', '移転先', 'の', '候補', '地', 'に', '上がら', 'ない', 'の', 'か', 'な', '？', '所属', 'の', 'タレント', 'が', '日常的', 'に', '使う', 'レッスン', '場', 'や', 'プロモーションビデオ', 'の', '撮影', 'など', 'に', 'もってこい', 'だ', 'と', '思う', 'けれど', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '会長', 'と', '本社', 'が', '河口湖', 'へ', '移転', 'し', 'て', '実務', 'の', '社員', 'は', 'TV', '局', 'や', '都心', 'に', '近い', '雑居ビル', 'に', '残る', 'の', 'で', 'は', '。', '取引先', 'が', 'そんな', '感じ', 'で', '青山', 'から', '地方', 'と', '郊外', 'に', '分散', '移転', 'し', 'た', 'よ', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '昨年', 'は', '、', '大手', 'の', '芸能事務所', 'から', 'の', '独立', '・', '退社', 'が', '相次ぎ', 'まし', 'た', '。', '今年', 'は', '、', 'さらに', '増える', 'でしょ', 'う', '。', '大手', 'の', '事務所', 'も', '、', '看板', 'と', '言わ', 'れる', '人', 'を', '月給', '制', 'で', '維持', 'し', 'て', 'ゆく', 'に', 'は', '環境', 'が', '厳しい', '。', 'と', '言っ', 'て', '、', 'いきなり', '歩合', '制', 'に', 'も', 'でき', 'ない', '。', 'なら', 'ば', '、', '赤坂', 'や', '青山', 'や', '表参道', 'に', '事務所', 'を', '置く', '理由', 'も', 'ない', 'し', '、', '今', 'の', '次期', 'です', 'から', '、', '事務所', 'も', 'リモートワーク', 'に', '徹すれ', 'ば', '良い', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '吉本興業', '東京', '本部', 'が', '2008年', 'から', '使っ', 'て', 'いる', 'の', 'は', '「', '旧', '新宿', '区立', '四谷', '第五小学校', '」', '。', '1934年', '竣工', 'の', '昭和', 'モダニズム建築', 'に', 'そっくり', 'そのまま', '入っ', 'て', 'いる', '。', '歌舞伎町', '、', '新宿ゴールデン街', '、', '花園神社', 'の', 'すぐ', '近く', '。', 'これ', 'は', '良い', '建物', '良い', '場所', 'を', '見つけ', 'た', 'な', 'と', '思っ', 'た', 'な', '。', '地代', 'や', '賃料', 'が', '高い', 'と', 'は', 'いえ', '、', '東京都内', 'に', 'は', 'まだまだ', '知ら', 'れ', 'て', 'い', 'ない', '穴場', '的', '場所', 'が', 'ある', '。', '空き', '物件', 'も', '増え', 'て', 'いる', 'し', '、', '意外', 'な', 'ところ', 'に', '意外', 'な', '事務所', 'が', 'ある', 'って', '言う', 'の', 'も', '、', '今後', 'は', '売り', 'に', 'なる', 'ん', 'じゃ', 'ない', 'か', '？', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '海外', 'ファンド', 'から', 'の', '買い', 'が', '多く', 'て', '東京都心', '部', 'の', '100', '単位', 'の', '不動産', 'は', '上がっ', 'て', 'い', 'ます', '。', 'エイベックス', 'は', '290億円', 'も', 'の', '売却', '益', 'を', '得', 'て', '、', 'イベント', 'の', '売上', '減少', 'に', '備え', 'て', 'しっかり', 'キャッシュ', 'を', '確保', 'でき', 'た', 'ので', '良い', 'とき', 'に', '売っ', 'た', 'の', 'で', 'は', '。', 'また', 'イベント', '売上', '減', 'で', 'トータル', 'の', '利益', 'は', 'かなり', '減っ', 'て', 'いる', '今', 'なら', '売却', '益', 'による', '納税額', 'も', '圧縮', '出来る', 'でしょ', 'う', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '新た', 'な', 'コロナ', 'の', '出現', '、', '地球温暖化', 'による', '異常気象', 'が', 'もたらす', '台風', 'の', '大型', '化', '、', '集中豪雨', 'に', '伴う', '都心', 'の', '河川', 'の', '氾濫', '、', '南極', '氷河', 'が', '溶け', 'て', '20年後', 'に', 'は', '海面', 'が', '1m', '上昇', 'する', 'と', '言わ', 'れ', 'て', 'いる', '。', '21年', 'は', '今', 'まで', 'の', '価値観', 'が', '大きく', '変わる', '年', '。', '都会', '、', '東京', 'に', '住む', 'こと', 'が', 'ステイタス', 'だっ', 'た', 'こと', 'が', 'これから', 'は', 'リスク', 'に', 'なる', '時代', 'な', 'ん', 'でしょ', 'う', '。', 'ここに', '既に', '気がつい', 'た', '人達', 'が', '避難', 'し', 'て', 'いる', 'の', 'でしょ', 'う', '。', '繁栄', 'を', '謳歌', 'し', '過ぎ', 'た', '人間', 'へ', 'の', 'しっぺ返し', '以外', 'の', '何もの', 'で', 'も', 'ない', 'でしょ', 'う', '。', '仕事', 'も', '学校', 'も', 'リモート', '化', 'で', '都心', 'に', '住む', '必要', 'も', '無い', 'こと', 'に', '気づい', 'た', '人達', '、', '言わば', '変化', 'に', '対応', '出来る', '人', 'だけ', 'が', '生き延びる', '。', 'そんな', '世界', 'が', 'き', 'て', 'い', 'ます', 'ね', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '東京', 'において', '、', '浅草', '無くし', 'て', '芸事', 'は', '無い', '。', 'です', 'ので', '、', '浅草', 'に', '事務所', 'を', '移す', 'なんて', '、', '下', 'に', '見', 'た', '言い方', 'は', 'まずい', 'か', 'と', '思い', 'ます', 'が', '…', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '河口湖', 'から', '1', '5時間', 'で', '東京', '…', '。', '新宿', 'なら', 'いい', 'けど', 'そこ', 'から', '先', 'だ', 'と', '速度', 'オーバー', 'に', 'なる', 'と', '思う', 'けど', 'な', '。', 'ただ', '中央道', 'の', '渋滞', 'を', '知ら', 'ない', 'の', 'か', 'なぁ', '。', '平日', 'の', '日中', 'で', 'も', '上り線', 'は', '混ん', 'で', 'いる', 'し', '土日', 'も', '朝一番', 'は', '上り線', 'は', '混ん', 'で', 'いる', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'ある日', '青山通り', 'を', '歩い', 'て', 'い', 'たら', '、', 'なん', 'か', '特別', 'な', '存在', '感', 'の', 'ある', 'ビル', 'の', '前', 'で', '立ち止まっ', 'た', '。', 'エイベックス', '？', '？', 'あの', 'エイベックス', 'の', 'ビル', '？', 'と', '視線', 'を', '上', 'に', 'し', 'て', 'ビル', 'を', '見上げ', 'た', '時', 'の', '感覚', 'が', '忘れ', 'られ', 'ない', '。', '広く', '取っ', 'た', '敷地', 'と', 'いい', '圧巻', 'でし', 'た', '。', 'なんとか', 'の', '夢', 'の', 'あと', '？', 'って', '感じ', 'です', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'お', '店', 'で', '言う', '薄利多売', 'で', 'は', 'ない', 'です', 'が', 'オフィスビル', '、', 'マンション', '、', '店舗', 'の', 'オーナー', 'さん', 'も', '長期', '機関', '借り', 'て', 'くれ', 'た', '店子', 'さん', '含め', '今後', 'は', '空い', 'たら', '特に', '都心', 'の', 'ビル', '等', 'は', '厳しい', 'でしょ', 'う', 'から', '家賃', 'を', '下げ', 'て', 'でも', 'そのまま', '契約', 'を', '更新', 'し', 'た', '方', 'が', '家賃', '収入', '0', 'より', 'は', '良い', 'の', 'で', 'は', '！', '売れ残り', 'を', '残す', 'より', 'セール', 'で', '売りさばく', 'の', 'と', '同じ', 'では', '？', '特に', '家賃', '収入', 'は', '商品', 'で', '言え', 'ば', '1', '個', 'だけ', '仕入れ', 'て', '複数', 'の', '人', 'に', '販売', 'する', 'の', 'と', '同じ', 'です', 'よ', 'ね', '！', 'これから', 'は', '大家さん', 'も', '欲', 'は', '欠か', 'ない', '！', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '浅草', 'は', '江戸時代', 'から', '歌舞伎', 'や', '大道芸人', 'を', '隔離', 'し', 'た', '猿若町', 'も', 'ある', 'し', '。', 'DEEP', 'で', '面白い', '歴史', 'の', '下町', '。', 'たけし', 'の', '足立区', 'や', '墨田区', 'も', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '大手', '事務所', 'も', '「', 'コロナ禍', '」', 'で', 'は', '、', '「', '観客動員', '」', 'の', 'イベント', 'が', '出来', 'ない', '。', '経営', 'の', '負担', 'と', 'なる', '都心', 'の', 'びる', 'の', '固定資産税', 'を', '考える', 'と', '売却', 'も', '正解', 'だろ', 'う', '。', 'ネット配信', 'で', '有れ', 'ば', '「', '撮影', '資材', 'と', '場所', '」', 'は', '日本中', 'に', '有る', '。', '今後', 'は', '各社', 'ネット', 'による', '営業', '展開', 'に', 'も', '力', 'が', '入る', 'だろ', 'う', '。', '総務省', 'も', 'ＮＨＫ', 'が', '使用', 'し', 'て', 'いる', '電波', 'を', 'この', '様', 'な', '業態', 'に', '入札', 'さ', 'せ', 'て', 'は', 'どう', 'だろ', 'う', 'か', '？', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'エイベックス', 'は', '完全', 'に', '音楽配信サービス', 'を', '軽視', 'し', 'て', '、', 'その', '波', 'に', '乗り遅れ', 'た', 'ツケ', 'が', '回っ', 'て', '来', 'たって', '感じ', 'か', 'な', '？', '何処', 'の', 'レコード会社', 'も', 'ＣＤ', 'や', 'ＤＶＤ', 'を', '売っ', 'て', 'は', '、', 'それ', 'を', '資金', 'に', 'ライブ', 'で', '儲ける', '手法', 'は', '、', 'この', 'コロナ禍', 'で', '完璧', 'な', 'まで', 'に', '壊れ', 'た', 'ね', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '都内', 'から', '河口湖', '付近', 'に', '通勤', 'する', 'の', 'は', '無理', 'と', '思う', '社員', 'が', '多い', 'でしょ', 'う', '。', '出勤', 'し', 'て', 'から', '都内', 'に', '出張', 'する', 'なんて', '・', '・', '・', '・', '。', '発案', '者', 'は', '１', '週間', '、', '都内', 'から', '河口湖', '近辺', 'に', '通勤', '体験', 'し', 'たら', '良い', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '青山', 'あたり', 'に', '本社', 'を', '構える', '会社', 'は', '今後', 'は', '蒲田', 'や', '赤', '羽', 'や', '錦糸町', 'や', '小岩', 'に', '移転', 'し', 'て', 'いき', 'そう', 'で', 'ある', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '事務所', 'の', 'コスト', 'カット', 'による', '移転', 'や', '事業', '縮小', 'による', 'タレント', 'や', 'スタッフ', 'の', 'リストラ', 'が', '発生', 'し', 'て', 'しまっ', 'た', '時点', 'で', '結局', '耐え', 'られ', 'なかっ', 'た', 'こと', 'に', 'なる', 'から', '仕方', 'ない', 'で', 'は', '済まさ', 'れ', 'ない', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '河口湖', 'いい', 'やん', '！', '昼休み', 'に', 'は', '釣り', 'が', '出来る', 'タレント', 'も', 'マネージャー', 'も', 'オフィス', 'に', '出勤', 'する', '意味', 'は', 'ない', 'から', 'いいんじゃない', 'まぁ', '河口湖', 'は', '極端', 'だ', 'けど', '千葉', '・', '神奈川', '・', '埼玉', 'なんて', '安い', '土地', 'や', '不動産', 'いくら', 'で', 'も', 'ある', 'から', 'その', '辺', 'で', 'も', 'いいんじゃない', '。', '[SEP]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テキストのデータ :\n",
      " ['[CLS]', '完全', '所有', '権', 'から', '区分所有権', 'に', 'し', 'て', '区分', 'を', '売却', '、', '持分', '割合', 'に', 'し', 'たら', 'コツコツ', '売却', '資金', '手', 'に', '出来', 'た', 'のに', 'な', '。', 'まぁ', '金融機関', 'が', 'ウン', 'と', 'は', '言わ', 'なかっ', 'た', 'か', '。', 'アイデア', 'が', 'なかっ', 'た', 'か', '。', '。', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '同じ', '移転', 'なら', '、', '三島', 'の', '方', 'が', 'よかっ', 'た', 'の', 'で', 'は', '。', '三島', 'なら', '、', '東京駅', 'まで', 'こだま', 'で', 'も', '１', '時間', 'あれ', 'ば', '着く', '近', 'さ', 'な', 'のに', '・', '・', '・', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '芸能事務所', 'が', '一般', 'に', '目', 'に', '付き', 'やすい', 'から', '記事', 'に', 'さ', 'れ', 'てる', 'だけ', 'で', '、', '普通に', 'BtoB', '企業', 'で', 'も', '脱', '都心', 'の', '案件', 'は', '数多い', 'だろ', 'う', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '青山', 'に', '本社', 'を', '構える', 'エイベックス', '、', '今後', 'は', '都内', 'の', '山手線', 'の', '外側', 'の', 'エリア', 'な', 'の', 'か', '、', '埼玉県', 'の', '和光市', 'や', '朝霞', '、', '志木', '、', '川越', '、', '森林公園', '、', '小川町', '、', '寄居', '、', '児玉', '、', 'そして', '群馬県', 'の', '高崎', 'に', '本社', 'を', '移転', 'し', 'て', 'き', 'そう', '？', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '浅草', 'も', '土地', '代', 'は', '安く', 'ない', 'が', '・', '・', '・', '朝日新聞出版', 'も', '、', '郊外', 'に', '移転', 'すれ', 'ば', 'いい', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '芸能人', 'にとって', 'は', '、', '演劇', 'や', 'ライブ', 'は', '明日', 'の', '食い扶持', 'を', '得る', 'ため', 'の', '生きる', '為', 'の', '必要', 'な', '行動', 'だ', '。', '決して', '不要不急', 'なんか', 'で', 'は', 'ない', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '昔', '、', 'この', 'ビル', 'の', '1階', 'で', '無料', 'で', 'インターネット', 'を', 'さ', 'せ', 'て', 'いただき', 'まし', 'た', '。', '感謝', 'し', 'て', 'い', 'ます', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'レプロ', 'も', '目黒', 'から', 'お茶の水', 'に', '引っ越す', 'よ', 'ね', '。', 'お茶の水', 'は', '出版社', 'が', '多い', '神保町', 'に', 'も', '近い', 'し', '、', '局', 'も', 'お台場', '以外', 'は', '意外と', '近い', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '世田谷区', 'や', '大田区', 'は', '空港', 'も', '近い', 'し', '東名', 'も', '近い', 'ぜ', '大田区', 'は', '高速', '乗っ', 'たら', '都内', 'の', '東側', 'で', 'も', '早く', '着く', 'オススメ', 'だ', 'ぜ', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '真相', 'は', '実態', 'を', '伴わ', 'ない', '株', '高', 'と', '近い', '将来', 'の', '不動産', '価格', 'の', '下落', 'を', '見越し', 'て', 'だろ', 'う', '。', 'お金持ち', 'の', '嗅覚', 'は', '鋭い', 'よ', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '「', 'ザ・ドリフターズ', '、', 'ビートたけし', '、', '渥美清', '、', '萩本欽一', '、', '美空ひばり', '、', '浅香光代', '、', '淡谷のり子', '、', '村田英雄', '、', '伊東四朗', '、', '水の江瀧子', '、', '沢村貞子', '、', '永六輔', 'ら', '・', '・', '・', '」', 'ビートたけし', '→', 'ツー・ビート', '萩本欽一', '→', 'コント55号', '伊東四朗', '→', 'てんぷくトリオ', 'と', '書い', 'て', '欲しかっ', 'た', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '芸能事務所', 'だけ', 'の', '問題', 'じゃ', 'なく', '、', '事務所', 'そのもの', 'の', '需要', 'が', 'コロナ', '後', '考える', '会社', '多く', '出', 'て', 'くる', '。', 'コロナ', 'の', '感染', 'どこ', 'で', '終息', 'なるか', 'だ', 'な', '。', '1', '極', '集中', 'が', '悪', 'だ', 'わ', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '浅草', 'に', '来', 'ない', 'と', '歴史', 'が', '変わる', '！', '葛飾郡', 'の', '歴史', '埋立地', 'は', 'ない', '時代', 'を', '話せ', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '相撲部屋', 'も', '今', 'じゃ', '両国', '辺り', 'だけ', 'じゃ', 'なく', '西新井', '、', '松戸', 'に', 'も', 'ある', 'から', 'ね', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'テレビ', 'に', '出す', 'より', 'Youtube', 'を', '頑張っ', 'た', 'ほう', 'が', '初期', '投資', 'を', '安く', '抑え', 'れる', 'もの', 'な', '。', '撮影', 'も', '映画', 'も', 'テレビ', 'で', 'わざわざ', '流す', '必要', 'が', 'ない', 'YouTube', 'の', '方', 'が', '遥か', 'に', '優れ', 'て', 'いる', '媒体', 'だ', 'と', '思う', '。', '今', 'の', 'テレビ局', 'って', '人', 'による', '技術', 'とか', 'が', '優位', '性', 'を', '保て', 'て', 'いる', 'だけ', 'で', '、', '白紙', 'から', '何', 'か', 'を', '作る', 'こと', 'に', 'は', '全く', '長け', 'て', 'い', 'ない', '。', 'YouTube', 'から', '新しい', 'チャンネル', 'が', '出来', 'て', 'いく', 'こと', 'を', '期待', 'し', 'て', 'い', 'ます', '。', '先行', '例', 'は', 'いくらでも', 'あり', 'ます', 'し', '芸人', 'さん', 'にとって', 'は', '本当に', '0', 'では', 'なく', '1', 'から', 'の', 'チャンス', 'だ', 'と', '思い', 'ます', 'よ', 'ね', '。', '撮影', 'できれ', 'ば', 'なん', 'でも', '出来る', 'わけ', 'です', 'から', '。', '賢', 'い人', 'は', 'それ', 'を', '規制', 'しよ', 'う', 'と', '考える', 'でしょ', 'う', 'が', '、', 'そもそも', '危ない', 'もの', 'は', 'YouTube', 'で', '自動', '削除', 'かかり', 'ます', 'から', 'ご', '安心', 'を', '。', 'テレビ', 'の', '既存', 'の', '考え方', 'は', '終わり', 'に', '向かう', 'という', 'こと', 'は', 'もはや', '既定路線', 'です', 'ので', '、', '今', 'まで', '他人', 'の', '不幸', 'で', '食っ', 'て', 'き', 'た', 'マスコミ', 'の', '罪深', 'さ', '、', 'これ', 'は', '発信', '者', 'が', 'とことん', '自家中毒', 'として', '味わっ', 'て', '頂き', 'たい', 'と', '思い', 'ます', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '河口湖', 'なんて', '有り得', 'ない', '。', 'また', '、', '一等地', 'から', '浅草', 'へ', 'って', '、', '浅草', 'も', '安く', '見', 'られ', 'た', 'もん', 'だ', 'な', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'ファン', 'が', 'ささえ', 'て', 'くれる', 'アーティスト', 'は', 'がん', 'が', 'れる', 'と', '思い', 'ます', '。', 'JUJU', '長渕', 'さだまさし', 'ゆず', '中島みゆき', 'サザン', '矢沢', '長渕', 'ゴスペラーズ', 'ユーミン', 'いきものがかり', 'miyavi', 'オレンジ', 'グリーン', '佐野', 'とか', '思いつく', '。', 'みんな', 'avex', 'じゃ', 'ない', 'の', 'ね', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '移転', 'し', 'て', 'も', 'エイベックス', 'は', '持た', 'ない', 'だろ', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '芸能人', 'も', '水商売', 'だ', 'から', 'ね', '。', '元々', '価値', 'の', '無い', 'もの', 'に', '人為', '的', 'に', '価値', 'を', 'つけ', 'て', 'いる', 'から', '落ちる', '時', 'は', '早い', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'レプロ', 'も', '目黒', 'から', '御茶ノ水', 'へ', '移転', 'する', 'し', 'ね', '。', 'まあ', '事務所', 'は', '山手線', 'の', '西側', 'が', 'おおい', 'よ', 'ね', '〜', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'まあ', '港区', 'とか', '目黒区', 'とか', 'じゃなくて', 'も', '、', '都内', 'で', '家賃', 'が', '安い', 'ところ', 'なら', 'いいんじゃない', '。', '河口湖', 'って', '…', '研修', 'なら', 'いい', 'が', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'TBS', 'の', '緑山', 'や', 'カンテレ', 'の', 'レモンスタジオ', '＆', '東京メディアシティ', 'に', '近く', '、', '比較的', '撮影', 'の', '多い', '京王線', 'に', 'も', '近い', '狛江', 'か', '多摩センター', '、', '町田', 'あたり', 'が', '良', 'さ', 'そう', 'だ', 'な', '。', '後', '、', '東京', 'に', 'も', '近い', '新横浜', 'か', '浦安', '、', '幕張', 'あたり', 'も', '。', '千葉', 'なら', 'ディズニーランド', 'や', '成田空港', 'が', 'ある', 'し', '、', 'この', 'ところ', '北総線', 'や', '東葉高速', 'で', 'の', '撮影', 'も', '多く', 'なっ', 'て', 'いる', 'から', '最適', 'かも', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'avex', 'って', 'レコード会社', 'でしょ', '？', '事務所', 'で', 'も', 'ある', 'ん', 'だろ', 'う', 'けど', '‥', 'まぁ', '会長', 'が', '薬物疑惑', 'ある', '会社', 'なんて', '、', 'あぁ', 'なる', 'よ', 'ね', '。', '笑える', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', 'うち', 'の', '会社', 'も', '移転', 'し', 'まし', 'た', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '逮捕', 'は', 'いつ', '？', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '薄っぺら', 'い記', '事', 'だ', 'なあ', '。', '「', '聞き', 'まし', 'た', '」', 'とか', '「', '某', '事務所', '」', 'とか', '内容', '皆無', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '色々', 'もう', '終わり', 'だ', 'な', '、', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '不要不急', 'だ', 'から', 'な', '（笑）', '…', '都心', '一', '等地', 'なんて', '会社', 'が', 'あっ', 'て', 'いい', '気', 'に', 'なっ', 'てる', 'けど', 'それで', 'ケチケチ', 'し', 'て', '利益', 'だけ', '伸ばし', 'てる', 'から', 'な', '…', 'バカバカしい', '！', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '河口湖', '？', 'ホンマ', 'かいな', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '調布', 'あたり', 'が', 'いいんじゃない', '？', '石原軍団', 'の', '事務所', 'って', '調布', 'だ', 'よ', 'ね', '映画', 'の', '撮影', '所', 'とか', 'スタジオ', 'とか', '色々', '近い', 'し', '芸能人', '結構', '住ん', 'でる', 'よ', 'ね', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '大', '歓', '迎', '！', 'どんどん', '地方', 'へ', '移転', 'を', 'お願い', 'いたし', 'ます', '。', '企業', 'も', '地方', '出身', '者', 'も', '都内', 'で', 'は', 'なく', '生まれ', 'た', '地域', 'で', '学び', '就職', 'し', '起業', 'し', '事業', '活動', 'し', 'て', 'ください', '！', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '2010年', 'ごろ', '、', 'この', 'ビル', 'に', '入っ', 'てる', '企業', 'に', '行く', '為', 'に', 'エレベーター', 'に', '乗っ', 'た', '時', 'に', 'avex', '社員', 'らしき', '女', 'の', '人', 'が', '薄手', 'の', '服', 'に', '巨乳', 'を', '露出', 'し', 'まくり', 'で', '入っ', 'て', 'き', 'た', '事', 'を', '思い出し', 'ます', '。', '仕事', '終わり', 'に', '、', 'そのまま', 'クラブ', 'に', '行く', 'つもり', 'だっ', 'た', 'ん', 'だろ', 'う', 'な', 'と', '。', 'イケイケ', 'の', '時代', 'の', '名残', 'でし', 'た', 'が', '、', 'あの', '時', 'は', '良かっ', 'た', 'という', '事', 'でしょ', 'う', 'か', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '浅草', 'は', '都心', 'の', '一等地', 'じゃ', 'ない', 'の', 'か', 'ｗ', '年寄り', 'に', 'は', '人気', 'ある', 'けど', 'ね', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '仕事', '上', 'は', 'そんな', '一等地', 'じゃなくて', 'も', '全然', '支障', 'ない', 'から', 'ね', '。', '当然', 'だろ', 'な', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '都心', 'の', '一等地', 'に', '事務所', 'なんて', '見栄', '以外', 'の', '何者', 'で', 'も', 'ない', 'から', 'な', '。', '結果', 'エーベックス', 'みたい', 'に', 'なる', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '本当', 'ただ', 'の', '妄想', 'コント', 'で', 'しか', 'ない', '記事', 'だ', 'ね', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '浅草', 'を', 'バカ', 'に', 'し', 'てる', 'の', 'か', '？', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '日本', 'の', 'ショービジネス', 'の', '人間', 'は', 'アマチュア', '。', '辞め', 'た', '方', 'が', '良い', '。', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '足立区', 'で', 'よい', 'の', 'で', 'は', '？', '[SEP]']\n",
      "テキストのデータ :\n",
      " ['[CLS]', '八王子', 'あたり', 'で', 'よく', 'ない', '？', '笑', '[SEP]']\n",
      "[60, 45, 57, 214, 55, 45, 93, 113, 82, 151, 35, 60, 72, 114, 32, 95, 60, 51, 29, 42, 52, 48, 37, 33, 53, 23, 32, 26, 31, 29, 31, 46, 41, 20, 19, 208, 25, 41, 11, 29, 24, 27, 75, 31, 11, 6, 21, 8, 35, 6, 32, 40, 84, 20, 19, 23, 13, 11, 16, 9, 9]\n",
      "max_token_number: 214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 学習データX\n",
    "# feature.csvは上記で用意したファイルのパスを指定してください\n",
    "train_features_df = pd.read_csv('./datasets/finetuning/train/features.csv')\n",
    "print(\"train_features_df:\\n\", train_features_df)\n",
    "\n",
    "\n",
    "# テキストの最初に[CLS]、最後に'[SEP]をつけて単語数を数える関数\n",
    "def _get_indice(feature):\n",
    "    tokens = []\n",
    "    tokens.append('[CLS]')\n",
    "    pre_text = preprocessing_text(feature)#追加\n",
    "    tokenized_text = tokenizer_mecab(pre_text)#追加\n",
    "    tokens.extend(tokenized_text)#追加\n",
    "    #tokens.extend(sp.encode_as_pieces(feature))# sentence piece\n",
    "    tokens.append('[SEP]')\n",
    "    print(\"テキストのデータ :\\n\",tokens)\n",
    "    number = len(tokens)\n",
    "    return number\n",
    "\n",
    "# sentence pieceでは、与えた文書の中で高い頻度で現れるフレーズは、\n",
    "# 多少長くても一つの単位として認識します。\n",
    "# Mecabでは対応する辞書を使って文章を分割します。辞書にはneologdとかがよく使われます。\n",
    "#これでも上手くいくことも多いですが、語彙数が大きくなってしまうことや、\n",
    "# 分割の仕方が分割したいデータセットに適していないこともあり、問題点\n",
    "#sp = spm.SentencePieceProcessor()\n",
    "\n",
    "# ダウンロードした事前学習モデルのパスを指定してください\n",
    "#sp.Load('./downloads/bert-wiki-ja/wiki-ja.model')\n",
    "\n",
    "numbers = []\n",
    "for feature in train_features_df['feature']:\n",
    "    features_number = _get_indice(feature)\n",
    "    numbers.append(features_number)\n",
    "\n",
    "print(numbers)\n",
    "\n",
    "# 最大トークン数\n",
    "max_token_num = max(numbers)\n",
    "print(\"max_token_number: \" + str(max_token_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTの設定ファイル、モデルのロード  \n",
    "学習回数と事前に調べていた最大トークン数、ファイルパスを自分用に書き換えてください。以下に書き換える箇所を示します。  \n",
    "\n",
    "- config_path：設定ファイルのパス  \n",
    "- checkpoint_path：事前学習モデルのファイルパス  \n",
    "    - 拡張子まで書かないでください  \n",
    "- SEQ_LEN：最大トークン数  \n",
    "- EPOCH：学習回数  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 214)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 214)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 214, 768), ( 24576000    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 214, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 214, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 214, 768)     164352      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 214, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 214, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 214, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 214, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 214, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 214, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 214, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 214, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 214, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 214, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 214, 768)     1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 214, 32000)   32000       MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       [(None, 214)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 214, 32000)   0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 111,014,146\n",
      "Trainable params: 111,014,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "\n",
    "#sys.pathに追加（必要なのか調査が必要）\n",
    "sys.path.append('modules')\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(sys.path)\n",
    "\n",
    "# BERTのロード\n",
    "config_path = './downloads/bert-wiki-ja_config/bert_finetuning_config_v1.json'\n",
    "# 拡張子まで記載しない（.ckptファイルで保存されている）\n",
    "checkpoint_path = './downloads//bert-wiki-ja/model.ckpt-1400000'\n",
    "\n",
    "# 最大のトークン数\n",
    "SEQ_LEN = max_token_num#上の処理の出力\n",
    "BATCH_SIZE = 16\n",
    "BERT_DIM = 768\n",
    "LR = 1e-4\n",
    "# 学習回数\n",
    "EPOCH = 20\n",
    "\n",
    "# 学習ずみモデルでモデル構築\n",
    "bert = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True,  trainable=True, seq_len=SEQ_LEN)\n",
    "bert.summary()\n",
    "\n",
    "# この後に追加する（転移学習）\n",
    "# 分類問題用にモデルの再構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データのロード関数\n",
    "こちらの関数でもモデルの読み込みを行うので、各自ファイルパスの変更をお願いします。\n",
    "\n",
    "- sp.load(\"ファイルパス\")\n",
    "\n",
    "## 文章のベクトル化\n",
    "_get_indice関数では、SentencePieceとwikipediaモデルを使用し文章のベクトル化を行っています\n",
    "\n",
    "## 学習データ読込\n",
    "_load_labeldata関数は学習データを読込、_get_indice関数を用いて特徴量を抽出しています。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "import numpy as np\n",
    "\n",
    "# ここでもsentence piece\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('./downloads/bert-wiki-ja/wiki-ja.model')\n",
    "\n",
    "# 上に同じ名前の関数があるので注意\n",
    "# 最大単語数分のID化された文を返す関数\n",
    "# maxlenがなくてエラーになるので勝手に追加（maxlenは最大単語数か？）\n",
    "def _get_indice(feature, maxlen):\n",
    "#def _get_indice(feature):\n",
    "    # インデックス ０で埋める\n",
    "    indices = np.zeros((maxlen), dtype = np.int32)\n",
    "    # 最初に[CLS]、最後に'[SEP]をつけてトークン作る\n",
    "    tokens = []\n",
    "    tokens.append('[CLS]')\n",
    "    pre_text = preprocessing_text(feature)#追加\n",
    "    tokenized_text = tokenizer_mecab(pre_text)#追加\n",
    "    tokens.extend(tokenized_text)#追加\n",
    "    #tokens.extend(sp.encode_as_pieces(feature))# sentence piece\n",
    "    tokens.append('[SEP]')\n",
    "\n",
    "    for t, token in enumerate(tokens):\n",
    "        # 最大単語数までトークンの単語をindicesに入れていく\n",
    "        if t >= maxlen:\n",
    "            break\n",
    "        try:\n",
    "            indices[t] = sp.piece_to_id(token)# id化してくれる？\n",
    "        except:\n",
    "            logging.warn(f'{token} is unknown.')# コメントしてくれる\n",
    "            indices[t] = sp.piece_to_id('<unk>')# id化してくれる？unknown\n",
    "    \n",
    "    # 最大単語数分のID化された文を返す\n",
    "    return indices\n",
    "\n",
    "\n",
    "#勝手に追加 maxlen=103  \n",
    "# 引数のパスは直接書けばいらないかも\n",
    "def _load_labeldata(train_dir, test_dir, maxlen):\n",
    "    # pandasでcsvの学習データとテストデータを読み込む\n",
    "    train_features_df = pd.read_csv(f'{train_dir}/features.csv')\n",
    "    train_labels_df = pd.read_csv(f'{train_dir}/labels.csv')\n",
    "    test_features_df = pd.read_csv(f'{test_dir}/features.csv')\n",
    "    test_labels_df = pd.read_csv(f'{test_dir}/labels.csv')\n",
    "    \n",
    "    ##### ラベル側の処理 #####\n",
    "    \n",
    "    # ラベルのユニーク値を取り出す（ラベル数）（インデックスとラベル別別に保管）\n",
    "    # ネガポジなら　ポジティブ, ネガティブ と　０、１　を入れてしまえばいいと思われる\n",
    "    #{'スポーツ': 0, '携帯電話': 1},\n",
    "    label2index = {k: i for i, k in enumerate(train_labels_df['label'].unique())}\n",
    "    #{0: 'スポーツ', 1: '携帯電話'}\n",
    "    index2label = {i: k for i, k in enumerate(train_labels_df['label'].unique())}\n",
    "    #　クラス数（何種類に分類するか）ネガポジなら２\n",
    "    class_count = len(label2index)\n",
    "    \n",
    "    # Numpyユーティリティ to_categorical(y, nb_classes=None)\n",
    "    # クラスベクトル（0からnb_classesまでの整数）を categorical_crossentropyとともに用いるためのバイナリのクラス行列に変換します．\n",
    "    # y: 行列に変換するクラスベクトル, nb_classes: 総クラス数\n",
    "    # ↓trainのラベルを文字からインデックスを使用して変換\n",
    "    train_labels = utils.np_utils.to_categorical([label2index[label] for label in train_labels_df['label']], num_classes=class_count)\n",
    "    #　testのインデックスをまず作る\n",
    "    test_label_indices = [label2index[label] for label in test_labels_df['label']]\n",
    "    # ↓testのラベルを文字からインデックスを使用して変換\n",
    "    test_labels = utils.np_utils.to_categorical(test_label_indices, num_classes=class_count)\n",
    "\n",
    "    ##### 特徴量側の処理 #####\n",
    "    \n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    for feature in train_features_df['feature']:\n",
    "        # 上で作った関数 _get_indice  を使ってID化\n",
    "        train_features.append(_get_indice(feature, maxlen))\n",
    "    # shape(len(train_features), maxlen)のゼロの行列作成\n",
    "    train_segments = np.zeros((len(train_features), maxlen), dtype = np.float32)\n",
    "\n",
    "    for feature in test_features_df['feature']:\n",
    "        # 上で作った関数 _get_indice  を使ってID化\n",
    "        test_features.append(_get_indice(feature, maxlen))\n",
    "    # shape(len(test_features), maxlen)のゼロの行列作成\n",
    "    test_segments = np.zeros((len(test_features), maxlen), dtype = np.float32)\n",
    "\n",
    "    print(f'Trainデータ数: {len(train_features_df)}, Testデータ数: {len(test_features_df)}, ラベル数: {class_count}')\n",
    "\n",
    "    return {\n",
    "        'class_count': class_count,\n",
    "        'label2index': label2index,\n",
    "        'index2label': index2label,\n",
    "        'train_labels': train_labels,\n",
    "        'test_labels': test_labels,\n",
    "        'test_label_indices': test_label_indices,\n",
    "        'train_features': np.array(train_features),\n",
    "        'train_segments': np.array(train_segments),\n",
    "        'test_features': np.array(test_features),\n",
    "        'test_segments': np.array(test_segments),\n",
    "        'input_len': maxlen\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 828,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_indice(\"制作\", maxlen=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainデータ数: 61, Testデータ数: 10, ラベル数: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_count': 2,\n",
       " 'label2index': {'positive': 0, 'negative': 1},\n",
       " 'index2label': {0: 'positive', 1: 'negative'},\n",
       " 'train_labels': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'test_labels': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32),\n",
       " 'test_label_indices': [1, 1, 1, 1, 0, 1, 1, 1, 1, 0],\n",
       " 'train_features': array([[    4,     0,    10, ...,     0,     0,     0],\n",
       "        [    4,    99,    10, ...,     0,     0,     0],\n",
       "        [    4, 28877,    10, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    4,    99,    10, ...,     0,     0,     0],\n",
       "        [    4,     0,    19, ...,     0,     0,     0],\n",
       "        [    4, 13693,  3964, ...,     0,     0,     0]], dtype=int32),\n",
       " 'train_segments': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'test_features': array([[    4,     0,    12, ...,     0,     0,     0],\n",
       "        [    4,  2134,     7, ...,     0,     0,     0],\n",
       "        [    4,  4302,   584, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    4, 28877,    10, ...,     0,     0,     0],\n",
       "        [    4,     0,    10, ...,     0,     0,     0],\n",
       "        [    4, 28877,   341, ...,     0,     0,     0]], dtype=int32),\n",
       " 'test_segments': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'input_len': 214}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_load_labeldata('./datasets/finetuning/train', './datasets/finetuning/test', maxlen=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# おそらく、この関数を作った理由は複数分類モデルを自由に作れるようにしたかったからだ。\n",
    "# 単にネガポジにするなら関数にしないで直接書けばいい。\n",
    "\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Flatten, GlobalMaxPooling1D\n",
    "from keras_bert.layers import MaskedGlobalMaxPool1D\n",
    "from keras import Input, Model\n",
    "\n",
    "# nadam を選べば使わなくてもいい\n",
    "# https://github.com/CyberZHG/keras-bert\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def _create_model(input_shape, class_count):\n",
    "    # AdamWarmupをオプティマイザーとして使用するために必要な情報を得る関数\n",
    "    # nadam を選べば使わなくてもいい\n",
    "    decay_steps, warmup_steps = calc_train_steps(\n",
    "        input_shape[0],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCH,\n",
    "    )\n",
    "\n",
    "    # 学習済みモデル 「bert」 の最終出力層のoutputを取り出す\n",
    "    bert_last = bert.get_layer(name='NSP-Dense').output\n",
    "    x1 = bert_last\n",
    "    # 最終出力層のoutputを新規作成した全結合層に入れる\n",
    "    output_tensor = Dense(class_count, activation='softmax')(x1)\n",
    "    \n",
    "    # Trainableの場合は、Input Masked Layerが3番目の入力なりますが、\n",
    "    # FineTuning時には必要無いので1, 2番目の入力だけ使用します。\n",
    "    # Trainableでなければkeras-bertのModel.inputそのままで問題ありません。\n",
    "    model = Model([bert.input[0], bert.input[1]], output_tensor)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=LR),\n",
    "                  #optimizer='nadam',\n",
    "                  metrics=['mae', 'mse', 'acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データのロードとモデルの準備\n",
    "事前準備で作成した学習用データと学習後のモデル名および出力先を指定してください。\n",
    "\n",
    "- trains_dir,tests_dir：学習用データのパス\n",
    "- model_filename：学習後のモデル名、出力先のパス\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import Input, Model, utils\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainデータ数: 61, Testデータ数: 10, ラベル数: 2\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 214)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 214)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 214, 768), ( 24576000    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 214, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 214, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 214, 768)     164352      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 214, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 214, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 214, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 214, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 214, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 214, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 214, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 214, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 214, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 214, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 214, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 214, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 214, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 214, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 214, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 214, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 214, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 214, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 214, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 110,390,018\n",
      "Trainable params: 110,390,018\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# データロードとモデルの準備\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "trains_dir = './datasets/finetuning/train'\n",
    "tests_dir = './datasets/finetuning/test'\n",
    "\n",
    "#上で作った関数\n",
    "data = _load_labeldata(trains_dir, tests_dir, SEQ_LEN)\n",
    "\n",
    "# モデルの読み込み\n",
    "model_filename = './downloads/models/knbc_finetuning.model'\n",
    "\n",
    "# 上で作った関数（関数を使わずに直接書くこともできる）\n",
    "# data['train_features'].shape　は　文の数×最大単語数　＝　特徴量Xのインプットshape\n",
    "# data['class_count']　は　クラスの数\n",
    "model = _create_model(data['train_features'].shape, data['class_count'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実行\n",
    "いよいよ学習の実行です。以下のプログラムを実行した際に画像のような出力が出ると思います。（tensorflowのバージョンでWarningが出ますが問題ありません）あとはお茶でも飲みながら学習経過を観察してみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファインチューニング？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 683s 155s/step - loss: 0.8308 - mae: 0.5402 - mse: 0.3145 - acc: 0.3660 - val_loss: 0.6466 - val_mae: 0.4584 - val_mse: 0.2277 - val_acc: 0.6000\n",
      "INFO:tensorflow:Assets written to: ./downloads/models/knbc_finetuning.model/assets\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 435s 110s/step - loss: 0.4363 - mae: 0.3271 - mse: 0.1339 - acc: 0.8871 - val_loss: 0.6272 - val_mae: 0.3890 - val_mse: 0.2299 - val_acc: 0.6000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 364s 96s/step - loss: 0.1853 - mae: 0.1532 - mse: 0.0432 - acc: 0.9705 - val_loss: 0.7420 - val_mae: 0.4041 - val_mse: 0.2704 - val_acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([data['train_features'], data['train_segments']],\n",
    "          data['train_labels'],\n",
    "          epochs = 3,\n",
    "          #epochs = EPOCH,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          validation_data=([data['test_features'], data['test_segments']], data['test_labels']),\n",
    "          shuffle=False,\n",
    "          verbose = 1,\n",
    "          callbacks = [\n",
    "              ModelCheckpoint(monitor='val_acc', mode='max', filepath=model_filename, save_best_only=True)\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価および予測\n",
    "### 評価の出力（不要）\n",
    "#### 学習経過\n",
    "学習回数毎の精度を算出し、学習経過を見ることが出来ます。  \n",
    "※ 学習を行った後に同じnotebookで実行してください。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.533783</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.646567</td>\n",
       "      <td>0.458439</td>\n",
       "      <td>0.227664</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423603</td>\n",
       "      <td>0.301595</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.627213</td>\n",
       "      <td>0.389006</td>\n",
       "      <td>0.229893</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164865</td>\n",
       "      <td>0.138192</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.741991</td>\n",
       "      <td>0.404056</td>\n",
       "      <td>0.270394</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss       mae       mse       acc  val_loss   val_mae   val_mse  \\\n",
       "0  0.831758  0.533783  0.313237  0.409836  0.646567  0.458439  0.227664   \n",
       "1  0.423603  0.301595  0.132501  0.868852  0.627213  0.389006  0.229893   \n",
       "2  0.164865  0.138192  0.037225  0.983607  0.741991  0.404056  0.270394   \n",
       "\n",
       "   val_acc  \n",
       "0      0.6  \n",
       "1      0.6  \n",
       "2      0.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル評価（不要）\n",
    "テストデータを用いて学習結果を算出出来ます。ここで用いられている指標については以下のURLを参照してください。\n",
    "http://tkdmah.hatenablog.com/entry/2014/02/22/193008\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>スポーツ</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>携帯電話</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "スポーツ              0.000   0.000     0.000      2.0\n",
       "携帯電話              0.750   0.750     0.750      8.0\n",
       "accuracy          0.600   0.600     0.600      0.6\n",
       "macro avg         0.375   0.375     0.375     10.0\n",
       "weighted avg      0.600   0.600     0.600     10.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import load_model\n",
    "from keras_bert import get_custom_objects\n",
    "\n",
    "model = load_model(model_filename, custom_objects=get_custom_objects())\n",
    "\n",
    "predicted_test_labels = model.predict([data['test_features'], data['test_segments']]).argmax(axis=1)\n",
    "numeric_test_labels = np.array(data['test_labels']).argmax(axis=1)\n",
    "\n",
    "report = classification_report(\n",
    "        numeric_test_labels, predicted_test_labels, target_names=['スポーツ', '携帯電話'], output_dict=True)\n",
    "# , '京都', 'スポーツ'\n",
    "display(pd.DataFrame(report).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論時にAttention Weightを出力するようにモデルをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "\n",
    "# custom_objects \n",
    "# custom_objects引数を使ってロード機構にそのカスタムレイヤーなどを渡すことができます\n",
    "#model = load_model(model_filename, custom_objects=SeqSelfAttention.get_custom_objects())\n",
    "\n",
    "#ModelクラスAPI   model = Model(inputs=a, outputs=b)  model = Model(inputs=[a1, a2], outputs=[b1, b2, b3])\n",
    "# model.get_layer('attention').output 2つ目のアウトプットを指定\n",
    "#model = Model(inputs=model.input, outputs=[model.output, model.get_layer('attention').output])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測\n",
    "いよいよ学習したモデルを用いた予測です。流れとしては入力された文章の特徴量を抽出し、モデルに入力するだけの簡単なお仕事です！ただ注意点もあります。それについては一度下記のソースを実行した後に解説します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'イギリスから戻って来た\\n布袋寅泰氏はどうするのかね\\n緊急事態宣言に\\n劇場とかは含まれないみたいだけど\\n全国からファンを\\n武道館に来させるのかな\\n中止もしくは\\n武道館に来なくても払い戻しします\\n位の措置は取った方がいいと思う\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_features_df = pd.read_csv('./datasets/pred_labeling/features_001.csv')\n",
    "tests_features_df.loc[0]['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from keras import utils\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import get_custom_objects\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "#sys.pathに追加（必要なのか調査が必要）\n",
    "sys.path.append('modules')\n",
    "\n",
    "# SentencePieceProccerモデルの読込\n",
    "spp = spm.SentencePieceProcessor()\n",
    "spp.Load('./downloads/bert-wiki-ja/wiki-ja.model')\n",
    "\n",
    "# BERTの学習したモデルの読込（ダウンロードした？勝手に保存される？）\n",
    "model_filename = './downloads/models/knbc_finetuning.model'\n",
    "model = load_model(model_filename, custom_objects=get_custom_objects())\n",
    "#model = load_model(model_filename, custom_objects=SeqSelfAttention.get_custom_objects())\n",
    "model = Model(inputs=model.input, outputs=[model.output, model.get_layer('Encoder-12-MultiHeadSelfAttention').output])\n",
    "# ↑ここでmodel = Model(inputs=a, outputs=b) としてAttentionも出すようにする。\n",
    "\n",
    "\n",
    "# 上のと同じのを入れると思われるため、消していいかも(ファイルを分けるなら必要)\n",
    "#SEQ_LEN = 103#206\n",
    "maxlen = SEQ_LEN\n",
    "#\n",
    "# 上にあったのと同じ？ → predictように変更\n",
    "def _get_indice_pred(feature, maxlen):\n",
    "    indices = np.zeros((maxlen), dtype=np.int32)\n",
    "\n",
    "    tokens = []\n",
    "    tokens.append('[CLS]')\n",
    "    pre_text = preprocessing_text(feature)#追加\n",
    "    tokenized_text = tokenizer_mecab(pre_text)#追加\n",
    "    tokens.extend(tokenized_text)#追加\n",
    "    #tokens.extend(spp.encode_as_pieces(feature))\n",
    "    tokens.append('[SEP]')\n",
    "\n",
    "    for t, token in enumerate(tokens):\n",
    "        if t >= maxlen:\n",
    "            break\n",
    "        try:\n",
    "            indices[t] = spp.piece_to_id(token)\n",
    "        except:\n",
    "            logging.warn('unknown')\n",
    "            indices[t] = spp.piece_to_id('<unk>')\n",
    "            \n",
    "    return indices, tokens\n",
    "\n",
    "tests_features_df = pd.read_csv('./datasets/pred_labeling/features_001.csv')\n",
    "feature = tests_features_df.loc[0]['feature']\n",
    "#feature = \"昨日は携帯電話を買いに行った。\"\n",
    "#feature = \"昨日はスポーツしに行った。\"\n",
    "\n",
    "test_features = []\n",
    "indices, tokens = _get_indice_pred(feature, maxlen)\n",
    "test_features.append(indices)\n",
    "\n",
    "#勝手に追加\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "test_segments = np.zeros(\n",
    "    (len(test_features), maxlen), dtype=np.float32)\n",
    "\n",
    "\n",
    "# model = Modelを使えば推定　predict[0][0]　２次元のリストで返せる。\n",
    "predicted_test_labels = model.predict([test_features, test_segments])#.argmax(axis=1)\n",
    "#predict = model.predict(test_features)\n",
    "\n",
    "\n",
    "print(\"完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'イギリス', 'から', '戻っ', 'て', '来', 'た', '布袋寅泰', '氏', 'は', 'どう', 'する', 'の', 'か', 'ね', '緊急事態宣言', 'に', '劇場', 'とか', 'は', '含ま', 'れ', 'ない', 'みたい', 'だ', 'けど', '全国', 'から', 'ファン', 'を', '武道館', 'に', '来さ', 'せる', 'の', 'か', 'な', '中止', 'もしくは', '武道', '館', 'に', '来', 'なく', 'て', 'も', '払い戻し', 'し', 'ます', '位', 'の', '措置', 'は', '取っ', 'た', '方', 'が', 'いい', 'と', '思う', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  2\n",
      "predict:  [[0.59652174 0.40347835]]\n",
      "predict:  [0]\n",
      "attention: (1, 214, 768)\n",
      "attention:\n",
      " [[[-0.15614392  0.11198843 -0.7218799  ... -0.43427202 -0.15799451\n",
      "    0.13034657]\n",
      "  [-0.20469886  0.40216246 -0.79378    ... -0.36917427 -0.27232108\n",
      "    0.30159944]\n",
      "  [ 0.22955036  0.48005208 -0.7393608  ... -0.8082622   0.52140796\n",
      "   -0.10452686]\n",
      "  ...\n",
      "  [-0.04775316  0.3499331  -0.30924207 ... -0.11876121 -0.22986516\n",
      "    0.13258928]\n",
      "  [-0.00219479  0.08754978 -0.21091847 ... -0.09936933 -0.21315327\n",
      "    0.09863827]\n",
      "  [-0.04547665  0.01744612 -0.15949327 ... -0.13492337 -0.17773315\n",
      "    0.08752056]]]\n",
      "attention:\n",
      " [[ 29  23  10  44  12  31   6  35  52  55  11  12  55  35  45  42   2  35\n",
      "   18  56   4  36  35  10  36  54  35  54  34  34   4  34  34  10   5  57\n",
      "    5  24  18  34  21  24  36  29  24  24  42  31  43  34   1  11  41  31\n",
      "   52  31   2  57  31  35  58  34  24  17  11   5   3  58  39  34   2  22\n",
      "   34  27  22  18  59  59  34 207  59  34   2  45  24  54   2  58  11  48\n",
      "   54   2  22  35  54   2  29  42  35  16  11   4   2  11  39  35   6   4\n",
      "   41  35  56  34  55  34  59  35  50  35  11  59  44   6   2   2   2  56\n",
      "   18   6  58  34  45  24  52  45  35  59  45  45  18   2  54  36  27  58\n",
      "   19  45  10  36  42  35  18  38  18  24  41  42   2  34  56   2  52  34\n",
      "   31  43  58  58  42  34  58  55  42  43  29  24  34  31  10  12   5  11\n",
      "   34   5  35   2  45  31   4  18   2  24   2   6  11  41  29  54  29  45\n",
      "   42  58   4  22  58  18  24   2  42  21  34  56   6  54  24   4  59   1\n",
      "   42   2  10  55  24   3  58   4   5   5  34  52  55  44   5  10  43  59\n",
      "    2  34  58  59  54  38  36  38  40   2  24  54  35  43  12  54   5  42\n",
      "    5  12  42  42   2  42  44  46  41  35  24  12  44  24  43  58  41   5\n",
      "   41  54  24  44  42  11  52  55   2  11   4   6  59  36  34  42  35  36\n",
      "    6  44  34  22  45  34   2  57  44  55  36  54   3  31  27   6  34 111\n",
      "   34  45   6  31  45   6  12   5   5  35  11  18   2  44  45  11  42  43\n",
      "   34  18  38  58  21  36  43   2  35  54  27   4  45  34  31  18  16  34\n",
      "   58  58  24  10  57  21  24  42  19  42  11  58  59  43  59  54  11  10\n",
      "   43   4  34  43   4  45  34  45  18  57   2  59   2  36   6  34  59  31\n",
      "   58  29  10  11  43  24   2  11  52  35  17  18  24  54  35  47  54  56\n",
      "   22  35  42  21  45  34  45  59  55  11  35  44   4  44  24  36   5  34\n",
      "   13  24  34  18  52  52   4  11  42  44  36  24  54 158  57  36   2  24\n",
      "   35  39  40  16   5  11  45  31  43   4  18   5  16  10   6   2  31  43\n",
      "   31  27  42  45  43  31   3  42  58  43  43   4  11   5  27  59   9  45\n",
      "   34  11  18  55  22  24  24  34  24   6   4   2  10  29  58   9  42  11\n",
      "    4  21  11  19  57  13  24  42  57   5  54  58  10  24   9  10  36  24\n",
      "   43  44  42  44  18  12  42  29   4  48   4  35   1  12   5  34  35  44\n",
      "   59  45  34   2  24  11  43   6  35  12  35  35   6  86  42  45  11  57\n",
      "   34  34  57   2  43  23   6  57  29  23  52   6  24  24 154  89   4  51\n",
      "   31  11  42  52   6  28  34  59  59   2   2   2   1  36  27  54  30   4\n",
      "   41   3  35  55  33  59  29  24   4  11  27   6  59  59  59   3  36   1\n",
      "   41  55  10  57  58  36  42   2  59  19  42   6  59  50  29   4   6  41\n",
      "   41  56  34  42  59  59  42  35  22  10  24  18  10   6  45  42  36   2\n",
      "   27  41  34  44  54  57  31  57  45   4  57  41  29  34  35   4  34   2\n",
      "   55  59  34   5  45  59  22  31  34  34  55   6  58   5  16  34   2  12\n",
      "   35  43  18  45  34   4  24  52  24  36  29  38  43  18  34  36  41  58\n",
      "    6  21  42  24  43  42  18   5  57   5   2  34  59  54  56  19   4   4\n",
      "   31  22  36  36  36   4   5  10  42  45  24  10   2  21  43  34   3  35\n",
      "   42  34  10   9  31  34  41  57  59  27  11  29  42  59   4  59  18  36\n",
      "   45  16  18  24  45  52  58   9  58   1  44   2  59  19  44  50   6  18\n",
      "   57  59  45  44  57  35  34   2  11  10   2   5]]\n",
      "attention:\n",
      " (1, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"shape: \", len(predicted_test_labels))\n",
    "#print(\"predicted_test_labels: \", predicted_test_labels)\n",
    "print(\"predict: \", predicted_test_labels[0])\n",
    "print(\"predict: \", predicted_test_labels[0].argmax(axis=1))\n",
    "print(\"attention:\", predicted_test_labels[1].shape)\n",
    "print(\"attention:\\n\", predicted_test_labels[1])\n",
    "print(\"attention:\\n\", predicted_test_labels[1].argmax(axis=1))#axis=1\n",
    "print(\"attention:\\n\", predicted_test_labels[1].argmax(axis=1).shape)#axis=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "Encoder-12-MultiHeadSelfAttenti (None, 206, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
    "                                                                 Encoder-12-MultiHeadSelfAttention\n",
    "__________________________________________________________________________________________________\n",
    "Encoder-12-MultiHeadSelfAttenti (None, 206, 768)     1536        Encoder-12-MultiHeadSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_08dba252_5ee0_11eb_8651_367dda54a607row0_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row1_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row2_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row3_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row4_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row5_col3 {\n",
       "            background-color:  #cbdef1;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row6_col3 {\n",
       "            background-color:  #f5f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row7_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row8_col3 {\n",
       "            background-color:  #7ab6d9;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row9_col3 {\n",
       "            background-color:  #63a8d3;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row10_col3 {\n",
       "            background-color:  #3282be;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row11_col3 {\n",
       "            background-color:  #d9e8f5;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row12_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row13_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row14_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row15_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row16_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row17_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row18_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row19_col3 {\n",
       "            background-color:  #dce9f6;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row20_col3 {\n",
       "            background-color:  #e0ecf8;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row21_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row22_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row23_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row24_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row25_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row26_col3 {\n",
       "            background-color:  #91c3de;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row27_col3 {\n",
       "            background-color:  #d9e8f5;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row28_col3 {\n",
       "            background-color:  #d9e7f5;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row29_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row30_col3 {\n",
       "            background-color:  #f3f8fe;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row31_col3 {\n",
       "            background-color:  #d9e8f5;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row32_col3 {\n",
       "            background-color:  #2a7ab9;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row33_col3 {\n",
       "            background-color:  #d4e4f4;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row34_col3 {\n",
       "            background-color:  #b4d3e9;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row35_col3 {\n",
       "            background-color:  #ecf4fb;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row36_col3 {\n",
       "            background-color:  #ccdff1;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row37_col3 {\n",
       "            background-color:  #6caed6;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row38_col3 {\n",
       "            background-color:  #f4f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row39_col3 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row40_col3 {\n",
       "            background-color:  #9cc9e1;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row41_col3 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row42_col3 {\n",
       "            background-color:  #d4e4f4;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row43_col3 {\n",
       "            background-color:  #f4f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row44_col3 {\n",
       "            background-color:  #bad6eb;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row45_col3 {\n",
       "            background-color:  #4292c6;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row46_col3 {\n",
       "            background-color:  #2c7cba;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row47_col3 {\n",
       "            background-color:  #b3d3e8;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row48_col3 {\n",
       "            background-color:  #eef5fc;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row49_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row50_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row51_col3 {\n",
       "            background-color:  #cddff1;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row52_col3 {\n",
       "            background-color:  #81badb;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row53_col3 {\n",
       "            background-color:  #cde0f1;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row54_col3 {\n",
       "            background-color:  #a8cee4;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row55_col3 {\n",
       "            background-color:  #d5e5f4;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row56_col3 {\n",
       "            background-color:  #8dc1dd;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row57_col3 {\n",
       "            background-color:  #92c4de;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row58_col3 {\n",
       "            background-color:  #3787c0;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row59_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_08dba252_5ee0_11eb_8651_367dda54a607row60_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_08dba252_5ee0_11eb_8651_367dda54a607\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >token</th>        <th class=\"col_heading level0 col1\" >weight</th>        <th class=\"col_heading level0 col2\" >rank</th>        <th class=\"col_heading level0 col3\" >normalized</th>        <th class=\"col_heading level0 col4\" >attention</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row0_col0\" class=\"data row0 col0\" >[CLS]</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row0_col1\" class=\"data row0 col1\" >0.481102</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row0_col2\" class=\"data row0 col2\" >56.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row1_col0\" class=\"data row1 col0\" >イギリス</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row1_col1\" class=\"data row1 col1\" >0.502085</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row1_col2\" class=\"data row1 col2\" >52.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row2_col0\" class=\"data row2 col0\" >から</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row2_col1\" class=\"data row2 col1\" >0.469868</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row2_col2\" class=\"data row2 col2\" >57.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row3_col0\" class=\"data row3 col0\" >戻っ</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row3_col1\" class=\"data row3 col1\" >0.539775</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row3_col2\" class=\"data row3 col2\" >50.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row4_col0\" class=\"data row4 col0\" >て</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row4_col1\" class=\"data row4 col1\" >0.560874</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row4_col2\" class=\"data row4 col2\" >49.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row4_col4\" class=\"data row4 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row5_col0\" class=\"data row5 col0\" >来</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row5_col1\" class=\"data row5 col1\" >0.766989</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row5_col2\" class=\"data row5 col2\" >20.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row5_col3\" class=\"data row5 col3\" >0.062607</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row5_col4\" class=\"data row5 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row6_col0\" class=\"data row6 col0\" >た</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row6_col1\" class=\"data row6 col1\" >0.708416</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row6_col2\" class=\"data row6 col2\" >38.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row6_col3\" class=\"data row6 col3\" >0.004033</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row6_col4\" class=\"data row6 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row7_col0\" class=\"data row7 col0\" >布袋寅泰</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row7_col1\" class=\"data row7 col1\" >0.594768</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row7_col2\" class=\"data row7 col2\" >48.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row7_col4\" class=\"data row7 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row8_col0\" class=\"data row8 col0\" >氏</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row8_col1\" class=\"data row8 col1\" >0.834359</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row8_col2\" class=\"data row8 col2\" >10.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row8_col3\" class=\"data row8 col3\" >0.129977</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row8_col4\" class=\"data row8 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row9_col0\" class=\"data row9 col0\" >は</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row9_col1\" class=\"data row9 col1\" >0.851253</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row9_col2\" class=\"data row9 col2\" >7.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row9_col3\" class=\"data row9 col3\" >0.146870</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row9_col4\" class=\"data row9 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row10_col0\" class=\"data row10 col0\" >どう</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row10_col1\" class=\"data row10 col1\" >0.896754</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row10_col2\" class=\"data row10 col2\" >4.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row10_col3\" class=\"data row10 col3\" >0.192372</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row10_col4\" class=\"data row10 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row11_col0\" class=\"data row11 col0\" >する</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row11_col1\" class=\"data row11 col1\" >0.746680</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row11_col2\" class=\"data row11 col2\" >29.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row11_col3\" class=\"data row11 col3\" >0.042297</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row11_col4\" class=\"data row11 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row12_col0\" class=\"data row12 col0\" >の</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row12_col1\" class=\"data row12 col1\" >0.640538</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row12_col2\" class=\"data row12 col2\" >45.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row12_col4\" class=\"data row12 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row13_col0\" class=\"data row13 col0\" >か</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row13_col1\" class=\"data row13 col1\" >0.525669</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row13_col2\" class=\"data row13 col2\" >51.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row13_col3\" class=\"data row13 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row13_col4\" class=\"data row13 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row14_col0\" class=\"data row14 col0\" >ね</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row14_col1\" class=\"data row14 col1\" >0.467445</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row14_col2\" class=\"data row14 col2\" >58.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row14_col3\" class=\"data row14 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row14_col4\" class=\"data row14 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row15_col0\" class=\"data row15 col0\" >緊急事態宣言</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row15_col1\" class=\"data row15 col1\" >0.429307</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row15_col2\" class=\"data row15 col2\" >60.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row15_col3\" class=\"data row15 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row15_col4\" class=\"data row15 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row16_col0\" class=\"data row16 col0\" >に</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row16_col1\" class=\"data row16 col1\" >0.676887</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row16_col2\" class=\"data row16 col2\" >42.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row16_col3\" class=\"data row16 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row16_col4\" class=\"data row16 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row17_col0\" class=\"data row17 col0\" >劇場</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row17_col1\" class=\"data row17 col1\" >0.685778</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row17_col2\" class=\"data row17 col2\" >41.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row17_col3\" class=\"data row17 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row17_col4\" class=\"data row17 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row18_col0\" class=\"data row18 col0\" >とか</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row18_col1\" class=\"data row18 col1\" >0.650617</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row18_col2\" class=\"data row18 col2\" >44.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row18_col3\" class=\"data row18 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row18_col4\" class=\"data row18 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row19_col0\" class=\"data row19 col0\" >は</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row19_col1\" class=\"data row19 col1\" >0.743405</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row19_col2\" class=\"data row19 col2\" >31.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row19_col3\" class=\"data row19 col3\" >0.039022</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row19_col4\" class=\"data row19 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row20_col0\" class=\"data row20 col0\" >含ま</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row20_col1\" class=\"data row20 col1\" >0.736985</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row20_col2\" class=\"data row20 col2\" >32.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row20_col3\" class=\"data row20 col3\" >0.032603</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row20_col4\" class=\"data row20 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row21_col0\" class=\"data row21 col0\" >れ</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row21_col1\" class=\"data row21 col1\" >0.497371</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row21_col2\" class=\"data row21 col2\" >53.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row21_col3\" class=\"data row21 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row21_col4\" class=\"data row21 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row22_col0\" class=\"data row22 col0\" >ない</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row22_col1\" class=\"data row22 col1\" >0.604266</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row22_col2\" class=\"data row22 col2\" >46.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row22_col3\" class=\"data row22 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row22_col4\" class=\"data row22 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row23_col0\" class=\"data row23 col0\" >みたい</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row23_col1\" class=\"data row23 col1\" >0.651004</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row23_col2\" class=\"data row23 col2\" >43.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row23_col3\" class=\"data row23 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row23_col4\" class=\"data row23 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row24_col0\" class=\"data row24 col0\" >だ</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row24_col1\" class=\"data row24 col1\" >0.596751</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row24_col2\" class=\"data row24 col2\" >47.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row24_col3\" class=\"data row24 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row24_col4\" class=\"data row24 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row25_col0\" class=\"data row25 col0\" >けど</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row25_col1\" class=\"data row25 col1\" >0.462235</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row25_col2\" class=\"data row25 col2\" >59.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row25_col3\" class=\"data row25 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row25_col4\" class=\"data row25 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row26_col0\" class=\"data row26 col0\" >全国</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row26_col1\" class=\"data row26 col1\" >0.819271</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row26_col2\" class=\"data row26 col2\" >13.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row26_col3\" class=\"data row26 col3\" >0.114888</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row26_col4\" class=\"data row26 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row27_col0\" class=\"data row27 col0\" >から</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row27_col1\" class=\"data row27 col1\" >0.746181</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row27_col2\" class=\"data row27 col2\" >30.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row27_col3\" class=\"data row27 col3\" >0.041798</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row27_col4\" class=\"data row27 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row28_col0\" class=\"data row28 col0\" >ファン</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row28_col1\" class=\"data row28 col1\" >0.747831</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row28_col2\" class=\"data row28 col2\" >27.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row28_col3\" class=\"data row28 col3\" >0.043448</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row28_col4\" class=\"data row28 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row29_col0\" class=\"data row29 col0\" >を</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row29_col1\" class=\"data row29 col1\" >0.703794</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row29_col2\" class=\"data row29 col2\" >39.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row29_col3\" class=\"data row29 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row29_col4\" class=\"data row29 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row30_col0\" class=\"data row30 col0\" >武道館</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row30_col1\" class=\"data row30 col1\" >0.709949</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row30_col2\" class=\"data row30 col2\" >35.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row30_col3\" class=\"data row30 col3\" >0.005566</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row30_col4\" class=\"data row30 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row31_col0\" class=\"data row31 col0\" >に</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row31_col1\" class=\"data row31 col1\" >0.746788</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row31_col2\" class=\"data row31 col2\" >28.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row31_col3\" class=\"data row31 col3\" >0.042406</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row31_col4\" class=\"data row31 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row32_col0\" class=\"data row32 col0\" >来さ</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row32_col1\" class=\"data row32 col1\" >0.905651</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row32_col2\" class=\"data row32 col2\" >2.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row32_col3\" class=\"data row32 col3\" >0.201268</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row32_col4\" class=\"data row32 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row33_col0\" class=\"data row33 col0\" >せる</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row33_col1\" class=\"data row33 col1\" >0.754531</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row33_col2\" class=\"data row33 col2\" >25.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row33_col3\" class=\"data row33 col3\" >0.050149</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row33_col4\" class=\"data row33 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row34_col0\" class=\"data row34 col0\" >の</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row34_col1\" class=\"data row34 col1\" >0.790338</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row34_col2\" class=\"data row34 col2\" >18.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row34_col3\" class=\"data row34 col3\" >0.085955</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row34_col4\" class=\"data row34 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row35_col0\" class=\"data row35 col0\" >か</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row35_col1\" class=\"data row35 col1\" >0.720522</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row35_col2\" class=\"data row35 col2\" >33.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row35_col3\" class=\"data row35 col3\" >0.016140</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row35_col4\" class=\"data row35 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row36_col0\" class=\"data row36 col0\" >な</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row36_col1\" class=\"data row36 col1\" >0.766193</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row36_col2\" class=\"data row36 col2\" >21.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row36_col3\" class=\"data row36 col3\" >0.061810</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row36_col4\" class=\"data row36 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row37_col0\" class=\"data row37 col0\" >中止</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row37_col1\" class=\"data row37 col1\" >0.844358</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row37_col2\" class=\"data row37 col2\" >9.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row37_col3\" class=\"data row37 col3\" >0.139975</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row37_col4\" class=\"data row37 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row38_col0\" class=\"data row38 col0\" >もしくは</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row38_col1\" class=\"data row38 col1\" >0.709322</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row38_col2\" class=\"data row38 col2\" >36.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row38_col3\" class=\"data row38 col3\" >0.004940</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row38_col4\" class=\"data row38 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row39_col0\" class=\"data row39 col0\" >武道</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row39_col1\" class=\"data row39 col1\" >0.845382</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row39_col2\" class=\"data row39 col2\" >8.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row39_col3\" class=\"data row39 col3\" >0.140999</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row39_col4\" class=\"data row39 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row40_col0\" class=\"data row40 col0\" >館</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row40_col1\" class=\"data row40 col1\" >0.810958</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row40_col2\" class=\"data row40 col2\" >15.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row40_col3\" class=\"data row40 col3\" >0.106575</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row40_col4\" class=\"data row40 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row41_col0\" class=\"data row41 col0\" >に</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row41_col1\" class=\"data row41 col1\" >0.984851</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row41_col2\" class=\"data row41 col2\" >1.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row41_col3\" class=\"data row41 col3\" >0.280468</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row41_col4\" class=\"data row41 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row42_col0\" class=\"data row42 col0\" >来</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row42_col1\" class=\"data row42 col1\" >0.754556</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row42_col2\" class=\"data row42 col2\" >24.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row42_col3\" class=\"data row42 col3\" >0.050174</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row42_col4\" class=\"data row42 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row43_col0\" class=\"data row43 col0\" >なく</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row43_col1\" class=\"data row43 col1\" >0.709263</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row43_col2\" class=\"data row43 col2\" >37.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row43_col3\" class=\"data row43 col3\" >0.004880</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row43_col4\" class=\"data row43 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row44_col0\" class=\"data row44 col0\" >て</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row44_col1\" class=\"data row44 col1\" >0.785228</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row44_col2\" class=\"data row44 col2\" >19.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row44_col3\" class=\"data row44 col3\" >0.080845</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row44_col4\" class=\"data row44 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row45_col0\" class=\"data row45 col0\" >も</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row45_col1\" class=\"data row45 col1\" >0.879555</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row45_col2\" class=\"data row45 col2\" >6.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row45_col3\" class=\"data row45 col3\" >0.175172</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row45_col4\" class=\"data row45 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row46_col0\" class=\"data row46 col0\" >払い戻し</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row46_col1\" class=\"data row46 col1\" >0.903224</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row46_col2\" class=\"data row46 col2\" >3.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row46_col3\" class=\"data row46 col3\" >0.198842</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row46_col4\" class=\"data row46 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row47_col0\" class=\"data row47 col0\" >し</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row47_col1\" class=\"data row47 col1\" >0.791536</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row47_col2\" class=\"data row47 col2\" >17.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row47_col3\" class=\"data row47 col3\" >0.087153</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row47_col4\" class=\"data row47 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row48_col0\" class=\"data row48 col0\" >ます</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row48_col1\" class=\"data row48 col1\" >0.717539</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row48_col2\" class=\"data row48 col2\" >34.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row48_col3\" class=\"data row48 col3\" >0.013156</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row48_col4\" class=\"data row48 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row49_col0\" class=\"data row49 col0\" >位</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row49_col1\" class=\"data row49 col1\" >0.693690</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row49_col2\" class=\"data row49 col2\" >40.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row49_col3\" class=\"data row49 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row49_col4\" class=\"data row49 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row50_col0\" class=\"data row50 col0\" >の</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row50_col1\" class=\"data row50 col1\" >0.488158</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row50_col2\" class=\"data row50 col2\" >54.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row50_col3\" class=\"data row50 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row50_col4\" class=\"data row50 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row51_col0\" class=\"data row51 col0\" >措置</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row51_col1\" class=\"data row51 col1\" >0.765567</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row51_col2\" class=\"data row51 col2\" >22.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row51_col3\" class=\"data row51 col3\" >0.061184</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row51_col4\" class=\"data row51 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row52_col0\" class=\"data row52 col0\" >は</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row52_col1\" class=\"data row52 col1\" >0.830301</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row52_col2\" class=\"data row52 col2\" >11.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row52_col3\" class=\"data row52 col3\" >0.125919</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row52_col4\" class=\"data row52 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row53_col0\" class=\"data row53 col0\" >取っ</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row53_col1\" class=\"data row53 col1\" >0.764475</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row53_col2\" class=\"data row53 col2\" >23.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row53_col3\" class=\"data row53 col3\" >0.060093</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row53_col4\" class=\"data row53 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row54_col0\" class=\"data row54 col0\" >た</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row54_col1\" class=\"data row54 col1\" >0.801531</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row54_col2\" class=\"data row54 col2\" >16.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row54_col3\" class=\"data row54 col3\" >0.097148</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row54_col4\" class=\"data row54 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row55_col0\" class=\"data row55 col0\" >方</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row55_col1\" class=\"data row55 col1\" >0.753344</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row55_col2\" class=\"data row55 col2\" >26.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row55_col3\" class=\"data row55 col3\" >0.048961</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row55_col4\" class=\"data row55 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row56_col0\" class=\"data row56 col0\" >が</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row56_col1\" class=\"data row56 col1\" >0.820886</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row56_col2\" class=\"data row56 col2\" >12.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row56_col3\" class=\"data row56 col3\" >0.116503</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row56_col4\" class=\"data row56 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row57_col0\" class=\"data row57 col0\" >いい</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row57_col1\" class=\"data row57 col1\" >0.817315</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row57_col2\" class=\"data row57 col2\" >14.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row57_col3\" class=\"data row57 col3\" >0.112932</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row57_col4\" class=\"data row57 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row58_col0\" class=\"data row58 col0\" >と</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row58_col1\" class=\"data row58 col1\" >0.890706</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row58_col2\" class=\"data row58 col2\" >5.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row58_col3\" class=\"data row58 col3\" >0.186324</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row58_col4\" class=\"data row58 col4\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row59_col0\" class=\"data row59 col0\" >思う</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row59_col1\" class=\"data row59 col1\" >0.486055</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row59_col2\" class=\"data row59 col2\" >55.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row59_col3\" class=\"data row59 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row59_col4\" class=\"data row59 col4\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08dba252_5ee0_11eb_8651_367dda54a607level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row60_col0\" class=\"data row60 col0\" >[SEP]</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row60_col1\" class=\"data row60 col1\" >0.387316</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row60_col2\" class=\"data row60 col2\" >61.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row60_col3\" class=\"data row60 col3\" >0.000000</td>\n",
       "                        <td id=\"T_08dba252_5ee0_11eb_8651_367dda54a607row60_col4\" class=\"data row60 col4\" >False</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe627299af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 入力シーケンスはpad_sequenceにより、以下の様に0でpre paddingしています。\n",
    "# [0 0 0 0 x1(300) x2(300) x3(300)]\n",
    "# Attention Weightは入力シーケンスに対応して計算されるため、\n",
    "# 入力シーケンスのpadding分シフトします。\n",
    "weights = [w.max() for w in predicted_test_labels[1][0][-len(tokens):]]\n",
    "df = pd.DataFrame([tokens, weights], index=['token', 'weight']).T\n",
    "\n",
    "mean = np.asarray(weights).mean()#np.asarray　参照コピー\n",
    "\n",
    "df['rank'] = df['weight'].rank(ascending=False)#ランキング\n",
    "# wから平均を引いた値が0より大きいものだけ（偏差）\n",
    "df['normalized'] = df['weight'].apply(lambda w: max(w - mean, 0))#行全体や列全体に対して、同じ操作\n",
    "df['weight'] = df['weight'].astype('float32')\n",
    "df['attention'] = df['normalized'] > 0\n",
    "# df.style.background_gradient で色つけ\n",
    "df = df.style.background_gradient(cmap='Blues', subset=['normalized'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測 作り直し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name:  features_001.csv\n",
      "pred_list:  [[-1], [-1]]\n",
      "good_ratio_list:  [[7.961538461538462], [11.466666666666667]]\n",
      "\n",
      "File Name:  features_003.csv\n",
      "pred_list:  [[-1], [-1]]\n",
      "good_ratio_list:  [[6.413897280966768], [9.019292604501608]]\n",
      "\n",
      "y_train:  [0, 0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from keras import utils\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import get_custom_objects\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "#sys.pathに追加（必要なのか調査が必要）\n",
    "sys.path.append('modules')\n",
    "\n",
    "# 上にあったのと同じ？ → predict用に変更\n",
    "def _get_indice_pred(feature, maxlen):\n",
    "    indices = np.zeros((maxlen), dtype=np.int32)\n",
    "\n",
    "    tokens = []\n",
    "    tokens.append('[CLS]')\n",
    "    pre_text = preprocessing_text(feature)#追加\n",
    "    tokenized_text = tokenizer_mecab(pre_text)#追加\n",
    "    tokens.extend(tokenized_text)#追加\n",
    "    #tokens.extend(spp.encode_as_pieces(feature))\n",
    "    tokens.append('[SEP]')\n",
    "\n",
    "    for t, token in enumerate(tokens):\n",
    "        if t >= maxlen:\n",
    "            break\n",
    "        try:\n",
    "            indices[t] = spp.piece_to_id(token)\n",
    "        except:\n",
    "            logging.warn('unknown')\n",
    "            indices[t] = spp.piece_to_id('<unk>')\n",
    "            \n",
    "    return indices, tokens\n",
    "\n",
    "\n",
    "# SentencePieceProccerモデルの読込\n",
    "spp = spm.SentencePieceProcessor()\n",
    "spp.Load('./downloads/bert-wiki-ja/wiki-ja.model')\n",
    "\n",
    "# BERTの学習したモデルの読込（ダウンロードした？勝手に保存される？）\n",
    "model_filename = './downloads/models/knbc_finetuning.model'\n",
    "model = load_model(model_filename, custom_objects=get_custom_objects())\n",
    "#model = load_model(model_filename, custom_objects=SeqSelfAttention.get_custom_objects())\n",
    "model = Model(inputs=model.input, outputs=[model.output, model.get_layer('Encoder-12-MultiHeadSelfAttention').output])\n",
    "# ↑ここでmodel = Model(inputs=a, outputs=b) としてAttentionも出すようにする。\n",
    "\n",
    "\n",
    "# 上のと同じのを入れると思われるため、消していいかも(ファイルを分けるなら必要)\n",
    "#SEQ_LEN = 103#206\n",
    "maxlen = SEQ_LEN\n",
    "\n",
    "y_train = []\n",
    "#for i in range(file_count):\n",
    "for i in range(3):\n",
    "    n_file = str(i+1).zfill(3)\n",
    "    file_name = \"features_\" + n_file + \".csv\"\n",
    "    f_path = (\"./datasets/pred_labeling/\" + file_name)\n",
    "    if not os.path.isfile(f_path):\n",
    "        continue\n",
    "\n",
    "    df_tests_features = pd.read_csv(f_path)\n",
    "    print(\"File Name: \", file_name)\n",
    "    \n",
    "    #excelファイル保管用\n",
    "    excel_file = './attention_excel/attention_' + n_file + '.xlsx'\n",
    "    writer = pd.ExcelWriter(excel_file, engine='xlsxwriter')\n",
    "        \n",
    "    wb = openpyxl.Workbook()\n",
    "    sheet = wb.active\n",
    "    sheet.title = 'Cover'\n",
    "    c1 = sheet[\"A1\"]\n",
    "    c2 = sheet[\"A2\"]\n",
    "    c1.value =  \"Attention出力用ファイルです。\"\n",
    "    c2.value =  \"詳細は次のシート以降を参照してください。\"\n",
    "    wb.save(excel_file)\n",
    "        \n",
    "        \n",
    "    pred_list = []\n",
    "    good_ratio_list = []\n",
    "#    for j in range(len(df_tests_features)):\n",
    "    for j in range(2):\n",
    "        feature = df_tests_features.loc[j]['feature']\n",
    "\n",
    "        test_features = []\n",
    "        indices, tokens = _get_indice_pred(feature, maxlen)\n",
    "        test_features.append(indices)\n",
    "\n",
    "        #勝手に追加\n",
    "        test_features = np.array(test_features)\n",
    "\n",
    "        test_segments = np.zeros(\n",
    "            (len(test_features), maxlen), dtype=np.float32)\n",
    "\n",
    "        # model = Modelを使えば推定　predict[0][0]　２次元のリストで返せる。\n",
    "        predicted = model.predict([test_features, test_segments])#.argmax(axis=1)\n",
    "        #predict = model.predict(test_features)\n",
    "\n",
    "        y_pred = predicted[0].argmax(axis=1)\n",
    "        #print(\"tokens: \", tokens)\n",
    "        #print(\"predict: \", y_pred[0])\n",
    "        \n",
    "        if y_pred[0] > 0.5:\n",
    "            pred_list.append([1])\n",
    "        else:\n",
    "            pred_list.append([-1])\n",
    "        \n",
    "        \n",
    "        # 高評価度算出\n",
    "        good = df_tests_features.loc[j]['good']\n",
    "        bad = df_tests_features.loc[j]['bad']\n",
    "        \n",
    "        if bad == 0:\n",
    "            good_ratio = [0]\n",
    "        else:\n",
    "            good_ratio = [good/bad]\n",
    "        \n",
    "        good_ratio_list.append(good_ratio)\n",
    "        \n",
    "        \n",
    "        # 入力シーケンスはpad_sequenceにより、以下の様に0でpre paddingしています。\n",
    "        # [0 0 0 0 x1(300) x2(300) x3(300)] ←３００は (None, 11, 300) の\n",
    "        # Attention Weightは入力シーケンスに対応して計算されるため、\n",
    "        # 入力シーケンスのpadding分シフトします。\n",
    "        #weights = [w.max() for w in predicted[1][0][-len(tokens):]]\n",
    "        weights = [w.max() for w in predicted[1][0]]#[-len(tokens):]\n",
    "        df = pd.DataFrame([tokens, weights], index=['token', 'weight']).T\n",
    "\n",
    "        mean = np.asarray(weights).mean()#np.asarray　参照コピー\n",
    "\n",
    "        df['rank'] = df['weight'].rank(ascending=False)#ランキング\n",
    "        # wから平均を引いた値が0より大きいものだけ（偏差）\n",
    "        df['normalized'] = df['weight'].apply(lambda w: max(w - mean, 0))#行全体や列全体に対して、同じ操作\n",
    "        df['weight'] = df['weight'].astype('float32')\n",
    "        df['attention'] = df['normalized'] > 0\n",
    "        # df.style.background_gradient で色つけ\n",
    "        df = df.style.background_gradient(cmap='Blues', subset=['normalized'])\n",
    "\n",
    "        # excel に保存\n",
    "        sheetname=\"comment\" + str(j)\n",
    "        with pd.ExcelWriter(excel_file, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            df.to_excel(writer, sheet_name=sheetname, index=False)\n",
    "        \n",
    "        #display(df)\n",
    "    \n",
    "    # 加重平均が０より大きいか\n",
    "    y = np.array(pred_list)*np.array(good_ratio_list)\n",
    "    \n",
    "    if y.mean() > 0:\n",
    "        y_train.append(1) \n",
    "    else:\n",
    "        y_train.append(0) \n",
    "        \n",
    "    print(\"pred_list: \", pred_list)\n",
    "    print(\"good_ratio_list: \", good_ratio_list)\n",
    "    print()\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "y_train_df.to_csv(\"./datasets/y_train.csv\")\n",
    "print(\"y_train: \", y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↑完成"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "モデルの保存も行う必要があるのでは。  \n",
    "チュートリアルより↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "#export_dir='./saved_model'\n",
    "#tf.saved_model.save(bert_classifier, export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復元\n",
    "#reloaded = tf.saved_model.load(export_dir)\n",
    "#reloaded_result = reloaded([my_examples['input_word_ids'],\n",
    "#                            my_examples['input_mask'],\n",
    "#                            my_examples['input_type_ids']], training=False)\n",
    "#\n",
    "#original_result = bert_classifier(my_examples, training=False)\n",
    "#\n",
    "# The results are (nearly) identical:\n",
    "#print(original_result.numpy())\n",
    "#print()\n",
    "#print(reloaded_result.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
